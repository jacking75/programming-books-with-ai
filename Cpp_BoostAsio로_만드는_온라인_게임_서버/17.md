# workingBooks  

저자: 최흥배, Claude AI   
    
권장 개발 환경
- **IDE**: Visual Studio 2022 (Community 이상)
- **컴파일러**: MSVC v143 (C++20 지원)
- **OS**: Windows 10 이상

-----  
  
# Chapter 17. 확장 가능한 서버 설계
확장 가능한 게임 서버 설계는 사용자 증가에 따른 서버 용량 확장을 위한 핵심 요소이다. 이번 장에서는 다양한 아키텍처 패턴, 로드 밸런싱, 데이터베이스 연동, 그리고 캐시 시스템을 활용하여 수평적/수직적 확장이 가능한 게임 서버를 설계하는 방법을 학습한다.


## 17.1 로드 밸런싱과 클러스터링

### 17.1.1 로드 밸런서 구현

```cpp
#include <algorithm>
#include <random>

// 백엔드 서버 정보
struct BackendServer
{
    std::string id;
    std::string host;
    uint16_t port;
    std::atomic<int> active_connections{0};
    std::atomic<int> total_requests{0};
    std::atomic<bool> is_healthy{true};
    std::chrono::steady_clock::time_point last_health_check;
    double response_time_avg = 0.0;
    
    void UpdateResponseTime(double new_time)
    {
        const double alpha = 0.1; // 가중 평균 계수
        response_time_avg = alpha * new_time + (1.0 - alpha) * response_time_avg;
    }
};

// 로드 밸런싱 전략 인터페이스
class LoadBalancingStrategy
{
public:
    virtual ~LoadBalancingStrategy() = default;
    virtual BackendServer* SelectServer(std::vector<BackendServer>& servers) = 0;
    virtual std::string GetStrategyName() const = 0;
};

// 라운드 로빈 전략
class RoundRobinStrategy : public LoadBalancingStrategy
{
public:
    BackendServer* SelectServer(std::vector<BackendServer>& servers) override
    {
        if (servers.empty())
            return nullptr;
            
        // 건강한 서버만 필터링
        std::vector<BackendServer*> healthy_servers;
        for (auto& server : servers)
        {
            if (server.is_healthy.load())
            {
                healthy_servers.push_back(&server);
            }
        }
        
        if (healthy_servers.empty())
            return nullptr;
            
        BackendServer* selected = healthy_servers[current_index_ % healthy_servers.size()];
        current_index_++;
        return selected;
    }
    
    std::string GetStrategyName() const override { return "Round Robin"; }

private:
    std::atomic<size_t> current_index_{0};
};

// 최소 연결 수 전략
class LeastConnectionsStrategy : public LoadBalancingStrategy
{
public:
    BackendServer* SelectServer(std::vector<BackendServer>& servers) override
    {
        if (servers.empty())
            return nullptr;
            
        BackendServer* best_server = nullptr;
        int min_connections = INT_MAX;
        
        for (auto& server : servers)
        {
            if (server.is_healthy.load())
            {
                int connections = server.active_connections.load();
                if (connections < min_connections)
                {
                    min_connections = connections;
                    best_server = &server;
                }
            }
        }
        
        return best_server;
    }
    
    std::string GetStrategyName() const override { return "Least Connections"; }
};

// 가중 응답 시간 전략
class WeightedResponseTimeStrategy : public LoadBalancingStrategy
{
public:
    BackendServer* SelectServer(std::vector<BackendServer>& servers) override
    {
        if (servers.empty())
            return nullptr;
            
        BackendServer* best_server = nullptr;
        double best_score = std::numeric_limits<double>::max();
        
        for (auto& server : servers)
        {
            if (server.is_healthy.load())
            {
                // 스코어 = 응답시간 + (연결수 * 가중치)
                double score = server.response_time_avg + 
                              (server.active_connections.load() * 10.0);
                              
                if (score < best_score)
                {
                    best_score = score;
                    best_server = &server;
                }
            }
        }
        
        return best_server;
    }
    
    std::string GetStrategyName() const override { return "Weighted Response Time"; }
};

// 로드 밸런서
class LoadBalancer
{
public:
    LoadBalancer(boost::asio::io_context& io_context, uint16_t port)
        : io_context_(io_context),
          acceptor_(io_context, boost::asio::ip::tcp::endpoint(boost::asio::ip::tcp::v4(), port)),
          health_check_timer_(io_context),
          strategy_(std::make_unique<RoundRobinStrategy>())
    {
        StartHealthChecks();
        StartAccepting();
    }

    void AddBackendServer(const std::string& id, const std::string& host, uint16_t port)
    {
        std::lock_guard<std::mutex> lock(servers_mutex_);
        
        BackendServer server;
        server.id = id;
        server.host = host;
        server.port = port;
        server.last_health_check = std::chrono::steady_clock::now();
        
        servers_.push_back(std::move(server));
        
        std::cout << "Backend server added: " << id << " (" << host << ":" << port << ")" << std::endl;
    }

    void RemoveBackendServer(const std::string& id)
    {
        std::lock_guard<std::mutex> lock(servers_mutex_);
        
        servers_.erase(
            std::remove_if(servers_.begin(), servers_.end(),
                [&id](const BackendServer& server) { return server.id == id; }),
            servers_.end());
            
        std::cout << "Backend server removed: " << id << std::endl;
    }

    void SetLoadBalancingStrategy(std::unique_ptr<LoadBalancingStrategy> strategy)
    {
        std::lock_guard<std::mutex> lock(strategy_mutex_);
        strategy_ = std::move(strategy);
        std::cout << "Load balancing strategy changed to: " << strategy_->GetStrategyName() << std::endl;
    }

    void PrintStatistics() const
    {
        std::lock_guard<std::mutex> lock(servers_mutex_);
        
        std::cout << "\n=== Load Balancer Statistics ===" << std::endl;
        std::cout << "Total requests processed: " << total_requests_.load() << std::endl;
        std::cout << "Active connections: " << active_connections_.load() << std::endl;
        std::cout << "Backend servers: " << servers_.size() << std::endl;
        
        for (const auto& server : servers_)
        {
            std::cout << "- " << server.id << " (" << server.host << ":" << server.port << ")" << std::endl;
            std::cout << "  Healthy: " << (server.is_healthy.load() ? "Yes" : "No") << std::endl;
            std::cout << "  Active connections: " << server.active_connections.load() << std::endl;
            std::cout << "  Total requests: " << server.total_requests.load() << std::endl;
            std::cout << "  Avg response time: " << std::fixed << std::setprecision(2) 
                     << server.response_time_avg << "ms" << std::endl;
        }
        std::cout << "================================" << std::endl;
    }

private:
    void StartAccepting()
    {
        acceptor_.async_accept([this](const boost::system::error_code& ec, 
                                     boost::asio::ip::tcp::socket client_socket)
        {
            if (!ec)
            {
                HandleConnection(std::move(client_socket));
            }
            StartAccepting();
        });
    }

    void HandleConnection(boost::asio::ip::tcp::socket client_socket)
    {
        BackendServer* backend = nullptr;
        {
            std::lock_guard<std::mutex> lock(servers_mutex_);
            std::lock_guard<std::mutex> strategy_lock(strategy_mutex_);
            backend = strategy_->SelectServer(servers_);
        }
        
        if (!backend)
        {
            std::cout << "No healthy backend servers available" << std::endl;
            return;
        }
        
        auto proxy_session = std::make_shared<ProxySession>(
            std::move(client_socket), *backend, io_context_);
        proxy_session->Start();
        
        backend->active_connections++;
        active_connections_++;
        total_requests_++;
    }

    void StartHealthChecks()
    {
        health_check_timer_.expires_after(std::chrono::seconds(10));
        health_check_timer_.async_wait([this](const boost::system::error_code& ec)
        {
            if (!ec)
            {
                PerformHealthChecks();
                StartHealthChecks();
            }
        });
    }

    void PerformHealthChecks()
    {
        std::lock_guard<std::mutex> lock(servers_mutex_);
        
        for (auto& server : servers_)
        {
            // 간단한 TCP 연결 테스트
            boost::asio::ip::tcp::socket test_socket(io_context_);
            boost::asio::ip::tcp::resolver resolver(io_context_);
            
            try
            {
                auto endpoints = resolver.resolve(server.host, std::to_string(server.port));
                boost::asio::connect(test_socket, endpoints);
                
                server.is_healthy = true;
                server.last_health_check = std::chrono::steady_clock::now();
                
                test_socket.close();
            }
            catch (const std::exception&)
            {
                server.is_healthy = false;
                std::cout << "Health check failed for server: " << server.id << std::endl;
            }
        }
    }

    class ProxySession : public std::enable_shared_from_this<ProxySession>
    {
    public:
        ProxySession(boost::asio::ip::tcp::socket client_socket, 
                    BackendServer& backend,
                    boost::asio::io_context& io_context)
            : client_socket_(std::move(client_socket)), 
              backend_socket_(io_context),
              backend_(backend),
              start_time_(std::chrono::steady_clock::now())
        {
        }

        ~ProxySession()
        {
            backend_.active_connections--;
            
            auto end_time = std::chrono::steady_clock::now();
            auto duration = std::chrono::duration_cast<std::chrono::milliseconds>(
                end_time - start_time_);
            backend_.UpdateResponseTime(duration.count());
        }

        void Start()
        {
            // 백엔드 서버에 연결
            boost::asio::ip::tcp::resolver resolver(backend_socket_.get_executor());
            auto endpoints = resolver.resolve(backend_.host, std::to_string(backend_.port));
            
            boost::asio::async_connect(backend_socket_, endpoints,
                [this, self = shared_from_this()](const boost::system::error_code& ec,
                                                  const boost::asio::ip::tcp::endpoint&)
                {
                    if (!ec)
                    {
                        StartProxying();
                        backend_.total_requests++;
                    }
                    else
                    {
                        std::cout << "Failed to connect to backend: " << ec.message() << std::endl;
                    }
                });
        }

    private:
        void StartProxying()
        {
            // 클라이언트 -> 백엔드
            DoReadFromClient();
            // 백엔드 -> 클라이언트
            DoReadFromBackend();
        }

        void DoReadFromClient()
        {
            auto self = shared_from_this();
            client_socket_.async_read_some(
                boost::asio::buffer(client_buffer_),
                [this, self](const boost::system::error_code& ec, std::size_t length)
                {
                    if (!ec)
                    {
                        DoWriteToBackend(length);
                    }
                });
        }

        void DoWriteToBackend(std::size_t length)
        {
            auto self = shared_from_this();
            boost::asio::async_write(
                backend_socket_,
                boost::asio::buffer(client_buffer_, length),
                [this, self](const boost::system::error_code& ec, std::size_t)
                {
                    if (!ec)
                    {
                        DoReadFromClient();
                    }
                });
        }

        void DoReadFromBackend()
        {
            auto self = shared_from_this();
            backend_socket_.async_read_some(
                boost::asio::buffer(backend_buffer_),
                [this, self](const boost::system::error_code& ec, std::size_t length)
                {
                    if (!ec)
                    {
                        DoWriteToClient(length);
                    }
                });
        }

        void DoWriteToClient(std::size_t length)
        {
            auto self = shared_from_this();
            boost::asio::async_write(
                client_socket_,
                boost::asio::buffer(backend_buffer_, length),
                [this, self](const boost::system::error_code& ec, std::size_t)
                {
                    if (!ec)
                    {
                        DoReadFromBackend();
                    }
                });
        }

        boost::asio::ip::tcp::socket client_socket_;
        boost::asio::ip::tcp::socket backend_socket_;
        BackendServer& backend_;
        std::chrono::steady_clock::time_point start_time_;
        
        std::array<char, 4096> client_buffer_;
        std::array<char, 4096> backend_buffer_;
    };

    boost::asio::io_context& io_context_;
    boost::asio::ip::tcp::acceptor acceptor_;
    boost::asio::steady_timer health_check_timer_;
    
    std::vector<BackendServer> servers_;
    mutable std::mutex servers_mutex_;
    
    std::unique_ptr<LoadBalancingStrategy> strategy_;
    mutable std::mutex strategy_mutex_;
    
    std::atomic<size_t> total_requests_{0};
    std::atomic<size_t> active_connections_{0};
};

void load_balancer_example()
{
    std::cout << "Load Balancer Example" << std::endl;
    
    boost::asio::io_context io_context;
    LoadBalancer load_balancer(io_context, 8080);
    
    // 백엔드 서버 추가
    load_balancer.AddBackendServer("backend1", "localhost", 8001);
    load_balancer.AddBackendServer("backend2", "localhost", 8002);
    load_balancer.AddBackendServer("backend3", "localhost", 8003);
    
    // 전략 변경 테스트
    std::thread strategy_test([&load_balancer]()
    {
        std::this_thread::sleep_for(std::chrono::seconds(5));
        load_balancer.SetLoadBalancingStrategy(std::make_unique<LeastConnectionsStrategy>());
        
        std::this_thread::sleep_for(std::chrono::seconds(5));
        load_balancer.SetLoadBalancingStrategy(std::make_unique<WeightedResponseTimeStrategy>());
    });
    
    // 통계 출력 스레드
    std::thread stats_thread([&load_balancer]()
    {
        while (true)
        {
            std::this_thread::sleep_for(std::chrono::seconds(10));
            load_balancer.PrintStatistics();
        }
    });
    
    std::cout << "Load balancer started on port 8080" << std::endl;
    std::cout << "Connect clients to test load balancing" << std::endl;
    
    io_context.run();
    
    strategy_test.join();
    stats_thread.detach();
}
```

### 17.2.2 서버 클러스터 관리

```cpp
// 클러스터 노드 정보
struct ClusterNode
{
    std::string node_id;
    std::string host;
    uint16_t port;
    std::string role; // "master", "slave", "worker"
    std::atomic<bool> is_alive{true};
    std::chrono::steady_clock::time_point last_heartbeat;
    std::unordered_map<std::string, std::string> metadata;
};

// 클러스터 관리자
class ClusterManager
{
public:
    ClusterManager(boost::asio::io_context& io_context, const std::string& node_id)
        : io_context_(io_context), local_node_id_(node_id), 
          heartbeat_timer_(io_context), election_timer_(io_context)
    {
        InitializeLocalNode();
        StartHeartbeat();
    }

    void JoinCluster(const std::string& seed_host, uint16_t seed_port)
    {
        std::cout << "Joining cluster via seed: " << seed_host << ":" << seed_port << std::endl;
        
        // 시드 노드에 연결하여 클러스터 정보 획득
        ConnectToSeedNode(seed_host, seed_port);
    }

    void AddNode(const ClusterNode& node)
    {
        std::lock_guard<std::mutex> lock(nodes_mutex_);
        nodes_[node.node_id] = node;
        
        std::cout << "Node added to cluster: " << node.node_id 
                 << " (" << node.role << ")" << std::endl;
    }

    void RemoveNode(const std::string& node_id)
    {
        std::lock_guard<std::mutex> lock(nodes_mutex_);
        auto it = nodes_.find(node_id);
        if (it != nodes_.end())
        {
            std::cout << "Node removed from cluster: " << node_id << std::endl;
            nodes_.erase(it);
        }
    }

    std::vector<ClusterNode> GetAliveNodes() const
    {
        std::lock_guard<std::mutex> lock(nodes_mutex_);
        std::vector<ClusterNode> alive_nodes;
        
        for (const auto& pair : nodes_)
        {
            if (pair.second.is_alive.load())
            {
                alive_nodes.push_back(pair.second);
            }
        }
        
        return alive_nodes;
    }

    void StartLeaderElection()
    {
        std::cout << "Starting leader election..." << std::endl;
        
        // 간단한 리더 선출 알고리즘 (노드 ID 기준)
        std::string highest_id = local_node_id_;
        
        {
            std::lock_guard<std::mutex> lock(nodes_mutex_);
            for (const auto& pair : nodes_)
            {
                if (pair.second.is_alive.load() && pair.first > highest_id)
                {
                    highest_id = pair.first;
                }
            }
        }
        
        if (highest_id == local_node_id_)
        {
            BecomeLeader();
        }
        else
        {
            std::cout << "Node " << highest_id << " is the new leader" << std::endl;
            current_leader_ = highest_id;
        }
    }

    void BroadcastMessage(const std::string& message)
    {
        auto alive_nodes = GetAliveNodes();
        
        for (const auto& node : alive_nodes)
        {
            if (node.node_id != local_node_id_)
            {
                SendMessageToNode(node, message);
            }
        }
    }

    void PrintClusterStatus() const
    {
        std::lock_guard<std::mutex> lock(nodes_mutex_);
        
        std::cout << "\n=== Cluster Status ===" << std::endl;
        std::cout << "Local Node: " << local_node_id_ << std::endl;
        std::cout << "Current Leader: " << current_leader_ << std::endl;
        std::cout << "Total Nodes: " << nodes_.size() << std::endl;
        
        size_t alive_count = 0;
        for (const auto& pair : nodes_)
        {
            const auto& node = pair.second;
            if (node.is_alive.load())
                alive_count++;
                
            std::cout << "- " << node.node_id << " (" << node.role << ") " 
                     << (node.is_alive.load() ? "ALIVE" : "DEAD") << std::endl;
        }
        
        std::cout << "Alive Nodes: " << alive_count << std::endl;
        std::cout << "======================" << std::endl;
    }

private:
    void InitializeLocalNode()
    {
        ClusterNode local_node;
        local_node.node_id = local_node_id_;
        local_node.host = "localhost";
        local_node.port = 9000 + std::hash<std::string>{}(local_node_id_) % 1000;
        local_node.role = "worker";
        local_node.last_heartbeat = std::chrono::steady_clock::now();
        
        std::lock_guard<std::mutex> lock(nodes_mutex_);
        nodes_[local_node_id_] = local_node;
    }

    void StartHeartbeat()
    {
        heartbeat_timer_.expires_after(std::chrono::seconds(5));
        heartbeat_timer_.async_wait([this](const boost::system::error_code& ec)
        {
            if (!ec)
            {
                SendHeartbeat();
                CheckNodesHealth();
                StartHeartbeat();
            }
        });
    }

    void SendHeartbeat()
    {
        // 자신의 하트비트 업데이트
        {
            std::lock_guard<std::mutex> lock(nodes_mutex_);
            auto it = nodes_.find(local_node_id_);
            if (it != nodes_.end())
            {
                it->second.last_heartbeat = std::chrono::steady_clock::now();
            }
        }
        
        // 다른 노드들에게 하트비트 전송
        BroadcastMessage("HEARTBEAT:" + local_node_id_);
    }

    void CheckNodesHealth()
    {
        std::lock_guard<std::mutex> lock(nodes_mutex_);
        auto now = std::chrono::steady_clock::now();
        
        bool leader_lost = false;
        
        for (auto& pair : nodes_)
        {
            auto& node = pair.second;
            if (node.node_id == local_node_id_)
                continue;
                
            auto duration = std::chrono::duration_cast<std::chrono::seconds>(
                now - node.last_heartbeat);
                
            if (duration.count() > 15) // 15초 이상 응답 없음
            {
                if (node.is_alive.load())
                {
                    std::cout << "Node " << node.node_id << " marked as dead" << std::endl;
                    node.is_alive = false;
                    
                    if (node.node_id == current_leader_)
                    {
                        leader_lost = true;
                    }
                }
            }
        }
        
        if (leader_lost)
        {
            std::cout << "Leader lost, starting election..." << std::endl;
            StartLeaderElection();
        }
    }

    void ConnectToSeedNode(const std::string& host, uint16_t port)
    {
        // 시드 노드 연결 및 클러스터 정보 요청
        boost::asio::ip::tcp::socket socket(io_context_);
        boost::asio::ip::tcp::resolver resolver(io_context_);
        
        try
        {
            auto endpoints = resolver.resolve(host, std::to_string(port));
            boost::asio::connect(socket, endpoints);
            
            // JOIN 메시지 전송
            std::string join_message = "JOIN:" + local_node_id_;
            boost::asio::write(socket, boost::asio::buffer(join_message));
            
            // 클러스터 정보 수신
            std::array<char, 4096> buffer;
            size_t length = socket.read_some(boost::asio::buffer(buffer));
            std::string response(buffer.data(), length);
            
            ProcessClusterInfo(response);
            
        }
        catch (const std::exception& e)
        {
            std::cerr << "Failed to connect to seed node: " << e.what() << std::endl;
        }
    }

    void ProcessClusterInfo(const std::string& info)
    {
        // 클러스터 정보 파싱 및 노드 목록 업데이트
        std::cout << "Received cluster info: " << info << std::endl;
        
        // 간단한 파싱 (실제로는 JSON 등 사용)
        // FORMAT: "NODES:node1,node2,node3"
        if (info.find("NODES:") == 0)
        {
            std::string nodes_str = info.substr(6);
            // 노드 목록 파싱 및 추가...
        }
    }

    void BecomeLeader()
    {
        std::cout << "Becoming cluster leader: " << local_node_id_ << std::endl;
        current_leader_ = local_node_id_;
        
        {
            std::lock_guard<std::mutex> lock(nodes_mutex_);
            auto it = nodes_.find(local_node_id_);
            if (it != nodes_.end())
            {
                it->second.role = "master";
            }
        }
        
        // 리더 공지
        BroadcastMessage("LEADER:" + local_node_id_);
    }

    void SendMessageToNode(const ClusterNode& node, const std::string& message)
    {
        // 실제 구현에서는 비동기로 처리
        try
        {
            boost::asio::ip::tcp::socket socket(io_context_);
            boost::asio::ip::tcp::resolver resolver(io_context_);
            
            auto endpoints = resolver.resolve(node.host, std::to_string(node.port));
            boost::asio::connect(socket, endpoints);
            
            boost::asio::write(socket, boost::asio::buffer(message));
        }
        catch (const std::exception& e)
        {
            std::cerr << "Failed to send message to " << node.node_id 
                     << ": " << e.what() << std::endl;
        }
    }

    boost::asio::io_context& io_context_;
    std::string local_node_id_;
    std::string current_leader_;
    
    std::unordered_map<std::string, ClusterNode> nodes_;
    mutable std::mutex nodes_mutex_;
    
    boost::asio::steady_timer heartbeat_timer_;
    boost::asio::steady_timer election_timer_;
};

void cluster_management_example()
{
    std::cout << "Cluster Management Example" << std::endl;
    
    boost::asio::io_context io_context;
    
    // 여러 노드 시뮬레이션
    std::vector<std::unique_ptr<ClusterManager>> nodes;
    std::vector<std::thread> node_threads;
    
    for (int i = 1; i <= 3; ++i)
    {
        std::string node_id = "node_" + std::to_string(i);
        auto cluster_manager = std::make_unique<ClusterManager>(io_context, node_id);
        
        // 첫 번째 노드가 아니면 클러스터 조인
        if (i > 1)
        {
            cluster_manager->JoinCluster("localhost", 9001);
        }
        
        nodes.push_back(std::move(cluster_manager));
    }
    
    // 상태 출력 스레드
    std::thread status_thread([&nodes]()
    {
        while (true)
        {
            std::this_thread::sleep_for(std::chrono::seconds(10));
            if (!nodes.empty())
            {
                nodes[0]->PrintClusterStatus();
            }
        }
    });
    
    std::cout << "Cluster started with " << nodes.size() << " nodes" << std::endl;
    
    // 클러스터 실행
    io_context.run();
    
    status_thread.detach();
}
```
   

</br>  
  

## 17.2 데이터베이스 연동

### 17.2.1 데이터베이스 연결 풀과 ORM

```cpp
#include <sqlite3.h>
#include <sstream>
#include <variant>

// 데이터베이스 값 타입
using DbValue = std::variant<std::monostate, int, double, std::string>;

// 데이터베이스 결과 행
using DbRow = std::unordered_map<std::string, DbValue>;

// SQLite 래퍼 클래스
class SQLiteConnection
{
public:
    explicit SQLiteConnection(const std::string& db_path)
        : db_(nullptr), db_path_(db_path)
    {
        Connect();
    }

    ~SQLiteConnection()
    {
        Disconnect();
    }

    bool Execute(const std::string& sql)
    {
        char* error_msg = nullptr;
        int result = sqlite3_exec(db_, sql.c_str(), nullptr, nullptr, &error_msg);
        
        if (result != SQLITE_OK)
        {
            std::cerr << "SQL error: " << error_msg << std::endl;
            sqlite3_free(error_msg);
            return false;
        }
        
        return true;
    }

    std::vector<DbRow> Query(const std::string& sql)
    {
        std::vector<DbRow> results;
        sqlite3_stmt* stmt = nullptr;
        
        int result = sqlite3_prepare_v2(db_, sql.c_str(), -1, &stmt, nullptr);
        if (result != SQLITE_OK)
        {
            std::cerr << "Failed to prepare statement: " << sqlite3_errmsg(db_) << std::endl;
            return results;
        }
        
        int column_count = sqlite3_column_count(stmt);
        
        while ((result = sqlite3_step(stmt)) == SQLITE_ROW)
        {
            DbRow row;
            
            for (int i = 0; i < column_count; ++i)
            {
                std::string column_name = sqlite3_column_name(stmt, i);
                int column_type = sqlite3_column_type(stmt, i);
                
                switch (column_type)
                {
                case SQLITE_INTEGER:
                    row[column_name] = sqlite3_column_int(stmt, i);
                    break;
                case SQLITE_FLOAT:
                    row[column_name] = sqlite3_column_double(stmt, i);
                    break;
                case SQLITE_TEXT:
                    row[column_name] = std::string(
                        reinterpret_cast<const char*>(sqlite3_column_text(stmt, i)));
                    break;
                case SQLITE_NULL:
                    row[column_name] = std::monostate{};
                    break;
                }
            }
            
            results.push_back(std::move(row));
        }
        
        sqlite3_finalize(stmt);
        return results;
    }

    bool IsConnected() const
    {
        return db_ != nullptr;
    }

    std::string GetLastError() const
    {
        return db_ ? sqlite3_errmsg(db_) : "Not connected";
    }

private:
    void Connect()
    {
        int result = sqlite3_open(db_path_.c_str(), &db_);
        if (result != SQLITE_OK)
        {
            std::cerr << "Failed to open database: " << sqlite3_errmsg(db_) << std::endl;
            db_ = nullptr;
        }
    }

    void Disconnect()
    {
        if (db_)
        {
            sqlite3_close(db_);
            db_ = nullptr;
        }
    }

    sqlite3* db_;
    std::string db_path_;
};

// 게임 엔티티 기본 클래스
class GameEntity
{
public:
    virtual ~GameEntity() = default;
    virtual void FromDbRow(const DbRow& row) = 0;
    virtual DbRow ToDbRow() const = 0;
    virtual std::string GetTableName() const = 0;
    virtual std::string GetIdColumn() const = 0;
    virtual DbValue GetId() const = 0;
};

// 플레이어 엔티티
class Player : public GameEntity
{
public:
    uint32_t player_id = 0;
    std::string username;
    std::string email;
    int level = 1;
    int experience = 0;
    int gold = 0;
    std::string created_at;
    std::string last_login;

    void FromDbRow(const DbRow& row) override
    {
        if (auto it = row.find("player_id"); it != row.end())
            player_id = std::get<int>(it->second);
        if (auto it = row.find("username"); it != row.end())
            username = std::get<std::string>(it->second);
        if (auto it = row.find("email"); it != row.end())
            email = std::get<std::string>(it->second);
        if (auto it = row.find("level"); it != row.end())
            level = std::get<int>(it->second);
        if (auto it = row.find("experience"); it != row.end())
            experience = std::get<int>(it->second);
        if (auto it = row.find("gold"); it != row.end())
            gold = std::get<int>(it->second);
        if (auto it = row.find("created_at"); it != row.end())
            created_at = std::get<std::string>(it->second);
        if (auto it = row.find("last_login"); it != row.end())
            last_login = std::get<std::string>(it->second);
    }

    DbRow ToDbRow() const override
    {
        DbRow row;
        row["player_id"] = static_cast<int>(player_id);
        row["username"] = username;
        row["email"] = email;
        row["level"] = level;
        row["experience"] = experience;
        row["gold"] = gold;
        row["created_at"] = created_at;
        row["last_login"] = last_login;
        return row;
    }

    std::string GetTableName() const override { return "players"; }
    std::string GetIdColumn() const override { return "player_id"; }
    DbValue GetId() const override { return static_cast<int>(player_id); }
};

// 간단한 ORM 클래스
template<typename EntityType>
class Repository
{
public:
    explicit Repository(std::shared_ptr<SQLiteConnection> connection)
        : connection_(connection)
    {
        static_assert(std::is_base_of_v<GameEntity, EntityType>, 
                     "EntityType must inherit from GameEntity");
    }

    bool Save(EntityType& entity)
    {
        if (std::get<int>(entity.GetId()) == 0)
        {
            return Insert(entity);
        }
        else
        {
            return Update(entity);
        }
    }

    std::optional<EntityType> FindById(int id)
    {
        EntityType entity;
        std::string sql = "SELECT * FROM " + entity.GetTableName() + 
                         " WHERE " + entity.GetIdColumn() + " = " + std::to_string(id);
        
        auto results = connection_->Query(sql);
        if (results.empty())
            return std::nullopt;
        
        entity.FromDbRow(results[0]);
        return entity;
    }

    std::vector<EntityType> FindAll()
    {
        EntityType entity;
        std::string sql = "SELECT * FROM " + entity.GetTableName();
        
        auto results = connection_->Query(sql);
        std::vector<EntityType> entities;
        
        for (const auto& row : results)
        {
            EntityType e;
            e.FromDbRow(row);
            entities.push_back(std::move(e));
        }
        
        return entities;
    }

    std::vector<EntityType> FindWhere(const std::string& condition)
    {
        EntityType entity;
        std::string sql = "SELECT * FROM " + entity.GetTableName() + " WHERE " + condition;
        
        auto results = connection_->Query(sql);
        std::vector<EntityType> entities;
        
        for (const auto& row : results)
        {
            EntityType e;
            e.FromDbRow(row);
            entities.push_back(std::move(e));
        }
        
        return entities;
    }

    bool Delete(int id)
    {
        EntityType entity;
        std::string sql = "DELETE FROM " + entity.GetTableName() + 
                         " WHERE " + entity.GetIdColumn() + " = " + std::to_string(id);
        
        return connection_->Execute(sql);
    }

private:
    bool Insert(EntityType& entity)
    {
        auto row = entity.ToDbRow();
        
        std::ostringstream columns, values;
        bool first = true;
        
        for (const auto& pair : row)
        {
            if (pair.first == entity.GetIdColumn())
                continue; // ID는 auto increment
                
            if (!first)
            {
                columns << ", ";
                values << ", ";
            }
            
            columns << pair.first;
            values << "'" << ValueToString(pair.second) << "'";
            first = false;
        }
        
        std::string sql = "INSERT INTO " + entity.GetTableName() + 
                         " (" + columns.str() + ") VALUES (" + values.str() + ")";
        
        if (connection_->Execute(sql))
        {
            // 생성된 ID 가져오기 (SQLite specific)
            auto results = connection_->Query("SELECT last_insert_rowid()");
            if (!results.empty())
            {
                // ID 업데이트 로직 (타입에 따라 구현 필요)
            }
            return true;
        }
        
        return false;
    }

    bool Update(const EntityType& entity)
    {
        auto row = entity.ToDbRow();
        
        std::ostringstream set_clause;
        bool first = true;
        
        for (const auto& pair : row)
        {
            if (pair.first == entity.GetIdColumn())
                continue; // ID는 WHERE 조건에 사용
                
            if (!first)
                set_clause << ", ";
                
            set_clause << pair.first << " = '" << ValueToString(pair.second) << "'";
            first = false;
        }
        
        std::string sql = "UPDATE " + entity.GetTableName() + 
                         " SET " + set_clause.str() + 
                         " WHERE " + entity.GetIdColumn() + " = " + 
                         ValueToString(entity.GetId());
        
        return connection_->Execute(sql);
    }

    std::string ValueToString(const DbValue& value)
    {
        return std::visit([](const auto& v) -> std::string
        {
            using T = std::decay_t<decltype(v)>;
            if constexpr (std::is_same_v<T, std::monostate>)
                return "NULL";
            else if constexpr (std::is_same_v<T, std::string>)
                return v;
            else
                return std::to_string(v);
        }, value);
    }

    std::shared_ptr<SQLiteConnection> connection_;
};

// 데이터베이스 서비스
class DatabaseService
{
public:
    explicit DatabaseService(const std::string& db_path)
        : connection_pool_(CreateConnectionFactory(db_path), 5, 20)
    {
        InitializeSchema();
    }

    Repository<Player> GetPlayerRepository()
    {
        auto connection = connection_pool_.AcquireConnection();
        return Repository<Player>(connection.Get());
    }

    void ExecuteTransaction(std::function<void(std::shared_ptr<SQLiteConnection>)> transaction)
    {
        auto connection_guard = connection_pool_.AcquireConnection();
        auto connection = connection_guard.Get();
        
        try
        {
            connection->Execute("BEGIN TRANSACTION");
            transaction(connection);
            connection->Execute("COMMIT");
        }
        catch (const std::exception& e)
        {
            connection->Execute("ROLLBACK");
            std::cerr << "Transaction failed: " << e.what() << std::endl;
            throw;
        }
    }

private:
    std::function<std::shared_ptr<SQLiteConnection>()> CreateConnectionFactory(const std::string& db_path)
    {
        return [db_path]() -> std::shared_ptr<SQLiteConnection>
        {
            return std::make_shared<SQLiteConnection>(db_path);
        };
    }

    void InitializeSchema()
    {
        auto connection_guard = connection_pool_.AcquireConnection();
        auto connection = connection_guard.Get();
        
        // 플레이어 테이블 생성
        std::string create_players_table = R"(
            CREATE TABLE IF NOT EXISTS players (
                player_id INTEGER PRIMARY KEY AUTOINCREMENT,
                username TEXT UNIQUE NOT NULL,
                email TEXT UNIQUE NOT NULL,
                level INTEGER DEFAULT 1,
                experience INTEGER DEFAULT 0,
                gold INTEGER DEFAULT 0,
                created_at TEXT DEFAULT CURRENT_TIMESTAMP,
                last_login TEXT DEFAULT CURRENT_TIMESTAMP
            )
        )";
        
        connection->Execute(create_players_table);
        
        std::cout << "Database schema initialized" << std::endl;
    }

    ConnectionPool<SQLiteConnection> connection_pool_;
};

void database_integration_example()
{
    std::cout << "Database Integration Example" << std::endl;
    
    DatabaseService db_service("game.db");
    
    // 플레이어 생성
    Player new_player;
    new_player.username = "testuser";
    new_player.email = "test@example.com";
    new_player.level = 5;
    new_player.experience = 1250;
    new_player.gold = 500;
    
    auto player_repo = db_service.GetPlayerRepository();
    
    // 플레이어 저장
    if (player_repo.Save(new_player))
    {
        std::cout << "Player saved successfully" << std::endl;
    }
    
    // 플레이어 조회
    auto players = player_repo.FindWhere("level >= 5");
    std::cout << "Found " << players.size() << " players with level >= 5" << std::endl;
    
    for (const auto& player : players)
    {
        std::cout << "- " << player.username << " (Level " << player.level 
                 << ", Gold " << player.gold << ")" << std::endl;
    }
    
    // 트랜잭션 예제
    db_service.ExecuteTransaction([&](std::shared_ptr<SQLiteConnection> connection)
    {
        // 여러 플레이어에게 골드 지급
        connection->Execute("UPDATE players SET gold = gold + 100 WHERE level >= 5");
        connection->Execute("INSERT INTO game_log (event, description) VALUES ('GOLD_BONUS', 'Level 5+ players received 100 gold')");
    });
    
    std::cout << "Transaction completed" << std::endl;
}
```
  
</br>  


## 17.3 Redis와 캐시 시스템 연동

### 17.3.1 Redis 클라이언트 구현

```cpp
#include <hiredis/hiredis.h>

// Redis 연결 래퍼
class RedisConnection
{
public:
    explicit RedisConnection(const std::string& host = "localhost", int port = 6379)
        : host_(host), port_(port), context_(nullptr)
    {
        Connect();
    }

    ~RedisConnection()
    {
        Disconnect();
    }

    bool Set(const std::string& key, const std::string& value, int ttl_seconds = 0)
    {
        redisReply* reply = nullptr;
        
        if (ttl_seconds > 0)
        {
            reply = static_cast<redisReply*>(
                redisCommand(context_, "SETEX %s %d %s", key.c_str(), ttl_seconds, value.c_str()));
        }
        else
        {
            reply = static_cast<redisReply*>(
                redisCommand(context_, "SET %s %s", key.c_str(), value.c_str()));
        }
        
        bool success = (reply && reply->type == REDIS_REPLY_STATUS && 
                       strcmp(reply->str, "OK") == 0);
        
        if (reply)
            freeReplyObject(reply);
            
        return success;
    }

    std::optional<std::string> Get(const std::string& key)
    {
        redisReply* reply = static_cast<redisReply*>(
            redisCommand(context_, "GET %s", key.c_str()));
        
        std::optional<std::string> result;
        
        if (reply)
        {
            if (reply->type == REDIS_REPLY_STRING)
            {
                result = std::string(reply->str, reply->len);
            }
            freeReplyObject(reply);
        }
        
        return result;
    }

    bool Delete(const std::string& key)
    {
        redisReply* reply = static_cast<redisReply*>(
            redisCommand(context_, "DEL %s", key.c_str()));
        
        bool success = (reply && reply->type == REDIS_REPLY_INTEGER && reply->integer > 0);
        
        if (reply)
            freeReplyObject(reply);
            
        return success;
    }

    bool Exists(const std::string& key)
    {
        redisReply* reply = static_cast<redisReply*>(
            redisCommand(context_, "EXISTS %s", key.c_str()));
        
        bool exists = (reply && reply->type == REDIS_REPLY_INTEGER && reply->integer > 0);
        
        if (reply)
            freeReplyObject(reply);
            
        return exists;
    }

    int64_t Increment(const std::string& key, int64_t by = 1)
    {
        redisReply* reply = static_cast<redisReply*>(
            redisCommand(context_, "INCRBY %s %lld", key.c_str(), by));
        
        int64_t result = 0;
        if (reply && reply->type == REDIS_REPLY_INTEGER)
        {
            result = reply->integer;
        }
        
        if (reply)
            freeReplyObject(reply);
            
        return result;
    }

    bool ListPush(const std::string& key, const std::string& value, bool left = true)
    {
        redisReply* reply = static_cast<redisReply*>(
            redisCommand(context_, left ? "LPUSH %s %s" : "RPUSH %s %s", 
                        key.c_str(), value.c_str()));
        
        bool success = (reply && reply->type == REDIS_REPLY_INTEGER);
        
        if (reply)
            freeReplyObject(reply);
            
        return success;
    }

    std::optional<std::string> ListPop(const std::string& key, bool left = true)
    {
        redisReply* reply = static_cast<redisReply*>(
            redisCommand(context_, left ? "LPOP %s" : "RPOP %s", key.c_str()));
        
        std::optional<std::string> result;
        
        if (reply)
        {
            if (reply->type == REDIS_REPLY_STRING)
            {
                result = std::string(reply->str, reply->len);
            }
            freeReplyObject(reply);
        }
        
        return result;
    }

    bool IsConnected() const
    {
        return context_ != nullptr && context_->err == 0;
    }

    std::string GetLastError() const
    {
        return context_ ? context_->errstr : "Not connected";
    }

private:
    void Connect()
    {
        context_ = redisConnect(host_.c_str(), port_);
        if (!context_ || context_->err)
        {
            std::cerr << "Redis connection failed: " 
                     << (context_ ? context_->errstr : "Cannot allocate redis context") << std::endl;
        }
    }

    void Disconnect()
    {
        if (context_)
        {
            redisFree(context_);
            context_ = nullptr;
        }
    }

    std::string host_;
    int port_;
    redisContext* context_;
};

// 캐시 매니저
class CacheManager
{
public:
    explicit CacheManager(const std::string& redis_host = "localhost", int redis_port = 6379)
        : redis_pool_(CreateRedisConnectionFactory(redis_host, redis_port), 5, 20)
    {
    }

    // 플레이어 데이터 캐싱
    bool CachePlayerData(uint32_t player_id, const Player& player, int ttl_seconds = 3600)
    {
        auto connection_guard = redis_pool_.AcquireConnection();
        auto redis = connection_guard.Get();
        
        std::string key = "player:" + std::to_string(player_id);
        std::string data = SerializePlayer(player);
        
        return redis->Set(key, data, ttl_seconds);
    }

    std::optional<Player> GetCachedPlayerData(uint32_t player_id)
    {
        auto connection_guard = redis_pool_.AcquireConnection();
        auto redis = connection_guard.Get();
        
        std::string key = "player:" + std::to_string(player_id);
        auto data = redis->Get(key);
        
        if (data)
        {
            return DeserializePlayer(*data);
        }
        
        return std::nullopt;
    }

    void InvalidatePlayerCache(uint32_t player_id)
    {
        auto connection_guard = redis_pool_.AcquireConnection();
        auto redis = connection_guard.Get();
        
        std::string key = "player:" + std::to_string(player_id);
        redis->Delete(key);
    }

    // 세션 관리
    bool CreateSession(const std::string& session_id, uint32_t player_id, int ttl_seconds = 7200)
    {
        auto connection_guard = redis_pool_.AcquireConnection();
        auto redis = connection_guard.Get();
        
        std::string key = "session:" + session_id;
        std::string value = std::to_string(player_id);
        
        return redis->Set(key, value, ttl_seconds);
    }

    std::optional<uint32_t> ValidateSession(const std::string& session_id)
    {
        auto connection_guard = redis_pool_.AcquireConnection();
        auto redis = connection_guard.Get();
        
        std::string key = "session:" + session_id;
        auto value = redis->Get(key);
        
        if (value)
        {
            try
            {
                return static_cast<uint32_t>(std::stoul(*value));
            }
            catch (const std::exception&)
            {
                return std::nullopt;
            }
        }
        
        return std::nullopt;
    }

    void InvalidateSession(const std::string& session_id)
    {
        auto connection_guard = redis_pool_.AcquireConnection();
        auto redis = connection_guard.Get();
        
        std::string key = "session:" + session_id;
        redis->Delete(key);
    }

    // 리더보드
    void UpdateLeaderboard(const std::string& leaderboard_name, uint32_t player_id, int score)
    {
        auto connection_guard = redis_pool_.AcquireConnection();
        auto redis = connection_guard.Get();
        
        std::string key = "leaderboard:" + leaderboard_name;
        std::string member = std::to_string(player_id);
        
        // Redis ZADD 명령 사용 (Sorted Set)
        // 실제 구현에서는 redisCommand로 ZADD 호출 필요
        std::cout << "Updating leaderboard " << leaderboard_name 
                 << ": player " << player_id << " score " << score << std::endl;
    }

    // 채팅 메시지 큐
    bool PublishChatMessage(const std::string& channel, const std::string& message)
    {
        auto connection_guard = redis_pool_.AcquireConnection();
        auto redis = connection_guard.Get();
        
        std::string queue_key = "chat:" + channel;
        
        // 메시지를 리스트에 추가 (최근 100개만 유지)
        if (redis->ListPush(queue_key, message, false)) // RPUSH
        {
            // 리스트 크기 제한 (실제로는 LTRIM 명령 사용)
            return true;
        }
        
        return false;
    }

    std::vector<std::string> GetRecentChatMessages(const std::string& channel, int count = 50)
    {
        auto connection_guard = redis_pool_.AcquireConnection();
        auto redis = connection_guard.Get();
        
        std::vector<std::string> messages;
        std::string queue_key = "chat:" + channel;
        
        // 실제로는 LRANGE 명령으로 구현
        for (int i = 0; i < count; ++i)
        {
            auto message = redis->ListPop(queue_key, true); // LPOP
            if (!message)
                break;
            messages.push_back(*message);
        }
        
        return messages;
    }

    // 통계 카운터
    void IncrementCounter(const std::string& counter_name, int64_t by = 1)
    {
        auto connection_guard = redis_pool_.AcquireConnection();
        auto redis = connection_guard.Get();
        
        std::string key = "counter:" + counter_name;
        redis->Increment(key, by);
    }

    int64_t GetCounter(const std::string& counter_name)
    {
        auto connection_guard = redis_pool_.AcquireConnection();
        auto redis = connection_guard.Get();
        
        std::string key = "counter:" + counter_name;
        auto value = redis->Get(key);
        
        if (value)
        {
            try
            {
                return std::stoll(*value);
            }
            catch (const std::exception&)
            {
                return 0;
            }
        }
        
        return 0;
    }

private:
    std::function<std::shared_ptr<RedisConnection>()> CreateRedisConnectionFactory(
        const std::string& host, int port)
    {
        return [host, port]() -> std::shared_ptr<RedisConnection>
        {
            return std::make_shared<RedisConnection>(host, port);
        };
    }

    std::string SerializePlayer(const Player& player)
    {
        // 간단한 JSON 형태로 직렬화 (실제로는 JSON 라이브러리 사용)
        std::ostringstream oss;
        oss << "{"
            << "\"player_id\":" << player.player_id << ","
            << "\"username\":\"" << player.username << "\","
            << "\"email\":\"" << player.email << "\","
            << "\"level\":" << player.level << ","
            << "\"experience\":" << player.experience << ","
            << "\"gold\":" << player.gold
            << "}";
        return oss.str();
    }

    Player DeserializePlayer(const std::string& data)
    {
        // 간단한 파싱 (실제로는 JSON 라이브러리 사용)
        Player player;
        
        // 파싱 로직 구현...
        // 여기서는 기본값 반환
        player.username = "cached_user";
        player.level = 1;
        
        return player;
    }

    ConnectionPool<RedisConnection> redis_pool_;
};

// 분산 캐시 시스템
class DistributedCacheService
{
public:
    DistributedCacheService()
    {
        // 여러 Redis 인스턴스 설정
        cache_managers_.emplace_back(std::make_unique<CacheManager>("redis1.example.com", 6379));
        cache_managers_.emplace_back(std::make_unique<CacheManager>("redis2.example.com", 6379));
        cache_managers_.emplace_back(std::make_unique<CacheManager>("redis3.example.com", 6379));
    }

    bool CachePlayerData(uint32_t player_id, const Player& player, int ttl_seconds = 3600)
    {
        size_t cache_index = player_id % cache_managers_.size();
        return cache_managers_[cache_index]->CachePlayerData(player_id, player, ttl_seconds);
    }

    std::optional<Player> GetCachedPlayerData(uint32_t player_id)
    {
        size_t cache_index = player_id % cache_managers_.size();
        return cache_managers_[cache_index]->GetCachedPlayerData(player_id);
    }

    void InvalidatePlayerCache(uint32_t player_id)
    {
        size_t cache_index = player_id % cache_managers_.size();
        cache_managers_[cache_index]->InvalidatePlayerCache(player_id);
    }

    // 전체 캐시에 브로드캐스트 (세션 무효화 등)
    void BroadcastInvalidation(const std::string& pattern)
    {
        for (auto& cache_manager : cache_managers_)
        {
            // 패턴에 맞는 키들 무효화
            std::cout << "Broadcasting invalidation pattern: " << pattern << std::endl;
        }
    }

private:
    std::vector<std::unique_ptr<CacheManager>> cache_managers_;
};

void redis_cache_example()
{
    std::cout << "Redis Cache System Example" << std::endl;
    
    CacheManager cache_manager;
    
    // 플레이어 데이터 캐싱
    Player player;
    player.player_id = 12345;
    player.username = "testplayer";
    player.email = "test@example.com";
    player.level = 25;
    player.experience = 50000;
    player.gold = 1500;
    
    // 캐시에 저장
    if (cache_manager.CachePlayerData(player.player_id, player, 3600))
    {
        std::cout << "Player data cached successfully" << std::endl;
    }
    
    // 캐시에서 조회
    auto cached_player = cache_manager.GetCachedPlayerData(player.player_id);
    if (cached_player)
    {
        std::cout << "Retrieved cached player: " << cached_player->username << std::endl;
    }
    
    // 세션 관리
    std::string session_id = "sess_" + std::to_string(std::time(nullptr));
    cache_manager.CreateSession(session_id, player.player_id, 7200);
    
    auto session_player_id = cache_manager.ValidateSession(session_id);
    if (session_player_id)
    {
        std::cout << "Valid session for player: " << *session_player_id << std::endl;
    }
    
    // 채팅 메시지
    cache_manager.PublishChatMessage("global", "Hello, world!");
    cache_manager.PublishChatMessage("global", "How is everyone?");
    
    auto messages = cache_manager.GetRecentChatMessages("global", 10);
    std::cout << "Recent chat messages: " << messages.size() << std::endl;
    
    // 통계 카운터
    cache_manager.IncrementCounter("players_online");
    cache_manager.IncrementCounter("total_logins", 5);
    
    std::cout << "Players online: " << cache_manager.GetCounter("players_online") << std::endl;
    std::cout << "Total logins: " << cache_manager.GetCounter("total_logins") << std::endl;
    
    // 분산 캐시 테스트
    DistributedCacheService distributed_cache;
    distributed_cache.CachePlayerData(player.player_id, player);
    
    auto distributed_player = distributed_cache.GetCachedPlayerData(player.player_id);
    if (distributed_player)
    {
        std::cout << "Retrieved from distributed cache: " << distributed_player->username << std::endl;
    }
}
```
  
</br>  

## 정리
이번 장에서는 확장 가능한 게임 서버 설계를 위한 핵심 요소들을 상세히 살펴보았다. 주요 내용을 요약하면:

1. **로드 밸런싱과 클러스터링**: 다양한 로드 밸런싱 전략과 클러스터 관리 시스템을 통해 서버 부하를 분산하고 고가용성을 확보하는 방법을 학습했습니다.

2. **데이터베이스 연동**: 연결 풀링과 간단한 ORM을 구현하여 데이터베이스 성능을 최적화하고 개발 효율성을 높이는 방법을 다뤘습니다.

3. **Redis와 캐시 시스템 연동**: 인메모리 캐시를 활용하여 데이터베이스 부하를 줄이고 응답 성능을 향상시키는 분산 캐시 시스템을 구축했습니다.

이러한 확장 가능한 설계 패턴들을 적절히 조합하면 사용자 증가에 유연하게 대응할 수 있는 게임 서버를 구축할 수 있습니다. 다음 장에서는 효율적인 네트워크 통신을 위한 프로토콜 설계와 직렬화 기법에 대해 학습하겠습니다.



  