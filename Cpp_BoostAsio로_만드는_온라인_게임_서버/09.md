# C++ Boost.Asio로 만드는 온라인 게임 서버
저자: 최흥배, Claude AI   
    
권장 개발 환경
- **IDE**: Visual Studio 2022 (Community 이상)
- **컴파일러**: MSVC v143 (C++20 지원)
- **OS**: Windows 10 이상
- **도구**: Windows Performance Toolkit, Intel VTune (선택사항)

-----   

# Chapter 9. 고급 비동기 기법
온라인 게임 서버 개발에서 비동기 프로그래밍은 핵심 기술이다. 이번 장에서는 Boost.Asio를 활용한 고급 비동기 기법들을 다루며, 실제 게임 서버에서 마주할 수 있는 복잡한 상황들을 효과적으로 처리하는 방법을 학습한다.

## 9.1 std::shared_ptr을 활용한 세션 관리
게임 서버에서 클라이언트 연결을 안전하게 관리하는 것은 매우 중요하다. std::shared_ptr을 활용하면 세션의 생명주기를 자동으로 관리할 수 있다.

### 9.1.1 스마트 포인터 기반 세션 클래스

```cpp
#include <boost/asio.hpp>
#include <boost/bind/bind.hpp>
#include <memory>
#include <iostream>
#include <array>

using boost::asio::ip::tcp;

class Session : public std::enable_shared_from_this<Session>
{
public:
    Session(tcp::socket socket) : socket_(std::move(socket))
    {
        std::cout << "Session created" << std::endl;
    }
    
    ~Session()
    {
        std::cout << "Session destroyed" << std::endl;
    }
    
    void Start()
    {
        DoRead();
    }
    
private:
    void DoRead()
    {
        auto self(shared_from_this());
        socket_.async_read_some(
            boost::asio::buffer(data_, max_length),
            [this, self](boost::system::error_code ec, std::size_t length)
            {
                if (!ec)
                {
                    ProcessData(length);
                    DoWrite(length);
                }
                else
                {
                    std::cout << "Read error: " << ec.message() << std::endl;
                }
            });
    }
    
    void DoWrite(std::size_t length)
    {
        auto self(shared_from_this());
        boost::asio::async_write(
            socket_, 
            boost::asio::buffer(data_, length),
            [this, self](boost::system::error_code ec, std::size_t /*length*/)
            {
                if (!ec)
                {
                    DoRead();
                }
                else
                {
                    std::cout << "Write error: " << ec.message() << std::endl;
                }
            });
    }
    
    void ProcessData(std::size_t length)
    {
        // 게임 로직 처리
        std::cout << "Processing " << length << " bytes" << std::endl;
    }
    
    tcp::socket socket_;
    enum { max_length = 1024 };
    char data_[max_length];
};
```
  
#### 핵심 개념 요약
1. 세션 수명 관리: `std::enable_shared_from_this<Session>`

* 세션은 반드시 `std::shared_ptr<Session>`로 소유해야 하며, 콜백 안에서 `shared_from_this()`로 자기 자신의 `shared_ptr`을 획득해 수명을 연장한다.
* 비동기 작업이 진행되는 동안 객체가 파괴되면 콜백에서 댕글링 포인터가 되므로, `auto self = shared_from_this();`를 캡처해 작업이 끝날 때까지 참조를 유지한다.
* 생성자 내부에서는 `shared_from_this()`를 호출할 수 없으므로, 일반적으로 `std::make_shared<Session>(std::move(socket))`로 생성한 뒤 `Start()`를 호출해야 한다.

2. 비동기 I/O 흐름

* `Start()` → `DoRead()` →(읽기 완료)→ `ProcessData()` → `DoWrite()` →(쓰기 완료)→ 다시 `DoRead()`로 순환한다.
* 이 예제는 받은 바이트를 그대로 다시 보내는 에코 로직이다.

3. 콜백에서 `[this, self]`를 모두 캡처하는 이유

* `self`는 수명 연장을 위한 소유 참조다.
* `this`는 멤버 접근을 간결하게 하기 위한 비소유 포인터다(필수는 아니나 가독성에 흔히 쓰인다). `self`가 있기 때문에 콜백 실행 동안 객체가 소멸되지 않는다.


#### 함수별 설명

생성/소멸자  

```cpp
Session(tcp::socket socket) : socket_(std::move(socket)) { ... }
~Session() { ... }
```

* `acceptor`에서 넘겨받은 소켓을 세션 내부로 이동시킨다.
* “created/destroyed” 로그로 수명 변화를 확인할 수 있다.

Start

```cpp
void Start() { DoRead(); }
```

* 세션을 구동하는 진입점이다. 첫 번째 비동기 읽기를 시작한다.

DoRead

```cpp
auto self(shared_from_this());
socket_.async_read_some(buffer(data_, max_length), [this, self](error_code ec, size_t length) { ... });
```

* 커널 수신 버퍼에서 가능한 만큼(최대 1024바이트) 읽어 온다.
* `async_read_some`은 “메시지 경계”를 보장하지 않으므로, 프로토콜이 있다면 분할/합쳐짐 처리(“반쪽/소시지 문제”)를 별도로 해야 한다.
* 성공 시 `ProcessData(length)` 호출 후 곧바로 `DoWrite(length)`로 에코를 보낸다. 실패 시 에러 로그만 남긴다(소켓은 범위 밖으로 나가며 소멸되면 닫힌다).

DoWrite

```cpp
auto self(shared_from_this());
boost::asio::async_write(socket_, buffer(data_, length), [this, self](error_code ec, size_t) { ... });
```

* 방금 읽은 `data_`를 그대로 보낸다.
* `async_write`는 요청한 길이 전체를 전송 완료할 때까지 내부적으로 반복 처리하므로, 부분 쓰기 핸들링은 필요 없다.
* 성공 시 다시 `DoRead()`를 호출해 루프를 이어 간다.

ProcessData

```cpp
void ProcessData(std::size_t length) { /* 게임 로직 처리 */ }
```

* 실제 서비스에서는 여기서 패킷 파싱, 명령 처리, 큐잉 등을 수행한다.
* 현재는 단순히 바이트 수를 출력하는 자리표시자다.

버퍼와 멤버들

```cpp
enum { max_length = 1024 };
char data_[max_length];
tcp::socket socket_;
```

* `data_`는 클래스 멤버이므로 비동기 작업 중에도 유효하다(중요한 수명 보장).
* 일시 객체나 지역 배열을 `buffer()`에 넘기는 것은 위험하다.


#### 동작 시나리오(요약)
1. `std::make_shared<Session>(std::move(socket))->Start();`로 시작한다.
2. `DoRead()`가 비동기 읽기를 건다(자기 수명 `self`로 연장).
3. 수신 완료 콜백에서 에러가 없으면 `ProcessData` → `DoWrite`.
4. 송신 완료 콜백에서 다시 `DoRead()`로 복귀한다.
5. 에러 발생 시 로그를 남기고 더 이상 다음 작업을 걸지 않으므로 참조가 풀리면 세션이 소멸한다.

  
### 9.1.2 세션 매니저 구현
여러 세션을 효율적으로 관리하기 위한 세션 매니저를 구현한다.

```cpp
#include <unordered_set>
#include <mutex>

class SessionManager
{
public:
    void AddSession(std::shared_ptr<Session> session)
    {
        std::lock_guard<std::mutex> lock(mutex_);
        sessions_.insert(session);
        std::cout << "Session added. Total: " << sessions_.size() << std::endl;
    }
    
    void RemoveSession(std::shared_ptr<Session> session)
    {
        std::lock_guard<std::mutex> lock(mutex_);
        sessions_.erase(session);
        std::cout << "Session removed. Total: " << sessions_.size() << std::endl;
    }
    
    void BroadcastMessage(const std::string& message)
    {
        std::lock_guard<std::mutex> lock(mutex_);
        for (auto& session : sessions_)
        {
            session->SendMessage(message);
        }
    }
    
    size_t GetSessionCount() const
    {
        std::lock_guard<std::mutex> lock(mutex_);
        return sessions_.size();
    }
    
private:
    std::unordered_set<std::shared_ptr<Session>> sessions_;
    mutable std::mutex mutex_;
};
```

### 9.1.3 RAII 패턴을 활용한 자동 세션 관리

```cpp
class AutoManagedSession : public std::enable_shared_from_this<AutoManagedSession>
{
public:
    AutoManagedSession(tcp::socket socket, SessionManager& manager)
        : socket_(std::move(socket)), manager_(manager)
    {
        manager_.AddSession(shared_from_this());
    }
    
    ~AutoManagedSession()
    {
        manager_.RemoveSession(shared_from_this());
    }
    
    void Start()
    {
        DoRead();
    }
    
    void SendMessage(const std::string& message)
    {
        auto self(shared_from_this());
        boost::asio::async_write(
            socket_,
            boost::asio::buffer(message),
            [this, self](boost::system::error_code ec, std::size_t /*length*/)
            {
                if (ec)
                {
                    std::cout << "Send error: " << ec.message() << std::endl;
                }
            });
    }
    
private:
    // DoRead, DoWrite 구현...
    
    tcp::socket socket_;
    SessionManager& manager_;
    enum { max_length = 1024 };
    char data_[max_length];
};
```  
   
</br>

## 9.2 패킷 처리와 프로토콜 설계
게임 서버에서는 다양한 타입의 패킷을 효율적으로 처리해야 한다.

### 9.2.1 패킷 헤더 정의

```cpp
#pragma pack(push, 1)
struct PacketHeader
{
    uint16_t packet_id;
    uint16_t packet_size;
    uint32_t sequence_number;
};

struct LoginPacket
{
    PacketHeader header;
    char user_id[32];
    char password[64];
};

struct ChatPacket
{
    PacketHeader header;
    char message[256];
};
#pragma pack(pop)

enum PacketType : uint16_t
{
    PACKET_LOGIN = 1001,
    PACKET_CHAT = 1002,
    PACKET_MOVE = 1003,
    PACKET_ATTACK = 1004
};
```

### 9.2.2 패킷 버퍼 클래스

```cpp
class PacketBuffer
{
public:
    PacketBuffer() : read_pos_(0), write_pos_(0) {}
    
    void Clear()
    {
        read_pos_ = 0;
        write_pos_ = 0;
    }
    
    bool HasCompletePacket() const
    {
        if (GetReadableSize() < sizeof(PacketHeader))
            return false;
            
        const PacketHeader* header = reinterpret_cast<const PacketHeader*>(
            buffer_.data() + read_pos_);
        return GetReadableSize() >= header->packet_size;
    }
    
    bool ReadPacket(std::vector<char>& packet_data)
    {
        if (!HasCompletePacket())
            return false;
            
        const PacketHeader* header = reinterpret_cast<const PacketHeader*>(
            buffer_.data() + read_pos_);
        
        packet_data.resize(header->packet_size);
        std::memcpy(packet_data.data(), buffer_.data() + read_pos_, 
                   header->packet_size);
        
        read_pos_ += header->packet_size;
        
        // 버퍼 최적화
        if (read_pos_ > buffer_.size() / 2)
        {
            std::memmove(buffer_.data(), buffer_.data() + read_pos_, 
                        GetReadableSize());
            write_pos_ -= read_pos_;
            read_pos_ = 0;
        }
        
        return true;
    }
    
    void WriteData(const char* data, size_t size)
    {
        if (write_pos_ + size > buffer_.size())
        {
            buffer_.resize(write_pos_ + size);
        }
        
        std::memcpy(buffer_.data() + write_pos_, data, size);
        write_pos_ += size;
    }
    
    char* GetWriteBuffer() { return buffer_.data() + write_pos_; }
    size_t GetWritableSize() const { return buffer_.size() - write_pos_; }
    size_t GetReadableSize() const { return write_pos_ - read_pos_; }
    void AdvanceWritePos(size_t size) { write_pos_ += size; }
    
private:
    std::vector<char> buffer_{8192}; // 초기 버퍼 크기
    size_t read_pos_;
    size_t write_pos_;
};
``` 
  
#### 핵심 동작 흐름
1. 수신 스레드가 `WriteData()`로 바이트를 이어 붙인다.
   * 내부 벡터 `buffer_`는 필요 시 `resize`로 커진다.
2. 소비 측이 `HasCompletePacket()`으로 “최소한 헤더만큼은 왔는가 → 헤더가 가리키는 길이만큼 전부 왔는가”를 검사한다.
3. `ReadPacket()`은 완전한 패킷이 있을 때 해당 길이만큼 `packet_data`로 복사하고 `read_pos_`를 전진시킨다.
4. 읽다 보면 앞부분이 비게 되므로, 읽은 양이 전체 버퍼의 절반을 넘으면 `memmove`로 뒤쪽 잔여 데이터를 앞으로 당기는 “압축(compact)”을 수행한다.

#### 주요 메서드 설명
* `WriteData(const char*, size_t)`
  쓰기 끝 위치(`write_pos_`) 뒤에 데이터를 붙인다. 공간이 모자라면 벡터를 키운다.
* `HasCompletePacket() const`
  ① 읽기 가능 바이트가 헤더 크기 미만이면 false
  ② 헤더를 읽어 `packet_size`를 얻고, 읽기 가능 바이트가 그 길이 이상이면 true
* `ReadPacket(std::vector<char>&)`
  완전한 패킷이 있으면 그 길이만큼 `packet_data`에 복사하고 포인터들을 갱신한다. 필요 시 버퍼를 압축한다.
* `GetReadableSize()` / `GetWritableSize()`
  현재 읽기 가능/쓰기 가능 길이를 계산한다.

#### 장점
* 단순한 선형 버퍼 모델이라 이해/디버깅이 쉽다.
* 조각 수신 → 헤더 기반 조립 → 패킷 단위 반환이라는 전형적 워크플로를 충실히 구현한다.
* 절반 넘게 읽었을 때만 압축해 `memmove` 빈도를 줄인다.

#### 주의사항과 개선 포인트
아래 항목들은 실서비스(특히 게임 서버)에서 반드시 챙길 부분이다.

1. 정렬(align) 및 엄격 별칭(strict aliasing) 문제 가능성이 있다
   현재 `reinterpret_cast<const PacketHeader*>`로 `char` 버퍼를 곧장 헤더로 해석한다. 주소 정렬이 보장되지 않으면 일부 아키텍처에서 UB가 된다.
   → **해결**: 로컬 변수에 `std::memcpy`로 헤더 바이트를 복사해 해석한다.

```cpp
PacketHeader hdr;
std::memcpy(&hdr, buffer_.data() + read_pos_, sizeof(PacketHeader));
```

2. 신뢰할 수 없는 `packet_size` 검증 부재다
   클라/공격자가 말도 안 되는 큰 길이를 쓰면, `HasCompletePacket()`은 계속 대기 상태가 되고 버퍼가 무한히 커질 수 있다(메모리 압박, DoS). 또한 헤더보다 작은 길이 등 비정상 값도 걸러야 한다.
   → **해결**: 최소/최대 길이 범위를 강제한다(예: `sizeof(PacketHeader) <= packet_size <= kMaxPacket`). 최대값은 프로토콜 상수로 고정한다.

3. 오버플로와 재할당 비용 관리가 필요하다

* `write_pos_ + size`가 `size_t` 오버플로가 될 수 있다. 사전 검사로 막아야 한다.
* `WriteData`가 정확히 필요한 만큼만 `resize`해 매번 재할당이 잦을 수 있다.
  → **해결**: “용량(capacity) 기반 성장” 정책을 도입한다(예: 1.5~2배 증가). `reserve()`와 별도 `EnsureWritable(size)` 헬퍼를 둔다.

4. 헤더/페이로드 엔디언 처리다
   네트워크 바이트 순서(빅엔디언)를 사용한다면 `packet_size`를 `ntohs/ntohl`로 변환해야 한다. 현재 코드는 호스트 엔디언 가정이다.
   → **해결**: 헤더 필드를 수신 즉시 변환한다.

5. 불필요한 복사 최소화가 필요하다
   `ReadPacket()`은 `packet_data`에 한 번 더 복사한다. 패킷 처리부가 즉시 파싱만 한다면, 복사 없이 바라보는 방식도 가능하다.
   → **대안**:

* 콜백에 `std::span<const char>`(또는 포인터+길이)로 넘기고, 처리가 끝나면 `read_pos_`만 전진한다.
* 또는 “링 버퍼 + 조각 보관”으로 zero-copy에 가깝게 설계한다.

6. 스레드 안정성이다
   이 구현은 멀티스레드 안전하지 않다. 보통 “한 연결당 수신 스레드 1개, 소비 스레드 1개” 패턴이면 락 없는 SPSC 큐나 메시지 큐로 분리하는 편이 안전하다. 최소한 `WriteData`와 `ReadPacket` 동시 호출 시엔 뮤텍스가 필요하다.

7. 압축 조건 및 축소 정책이다
   `read_pos_ > buffer_.size()/2` 조건은 단순하면서도 괜찮지만, 대형 버퍼가 한 번 만들어지면 오래 유지된다.
   → **개선**: 읽기 구간이 작고 전체 용량이 너무 크면 `shrink_to_fit()`나 “상한치 이하로 내려가면 축소” 정책을 추가한다.

8. API 안전성이다

* `AdvanceWritePos(size)`는 사전 `EnsureWritable(size)` 없이 쓰면 손상 가능성이 있다.
* `GetWriteBuffer()`를 외부에서 받은 뒤 `WriteData()`가 capacity를 바꾸면 포인터가 무효화된다.
  → **해결**: 외부가 직접 버퍼를 건드릴 필요가 없도록 `WriteData()`/`EnsureWritable()`만 제공하거나, “예약 후 포인터 제공 → 반드시 `AdvanceWritePos()`로 확정”의 사용 규약을 문서화한다.

#### 사용 예시
소켓에서 받은 바이트를 계속 밀어 넣고, 가능한 만큼 패킷을 뽑아 처리하면 된다.

```cpp
PacketBuffer buf;
char tmp[4096];

int n = ::recv(fd, tmp, sizeof(tmp), 0);
if (n > 0) {
    buf.WriteData(tmp, static_cast<size_t>(n));
    std::vector<char> packet;
    while (buf.ReadPacket(packet)) {
        // packet에는 [헤더+바디]가 통째로 담겨 있다
        // 파싱/핸들링 수행
    }
}
```

  
### 9.2.3 패킷 처리기 구현

```cpp
class PacketProcessor
{
public:
    using PacketHandler = std::function<void(const char*, size_t)>;
    
    void RegisterHandler(uint16_t packet_id, PacketHandler handler)
    {
        handlers_[packet_id] = handler;
    }
    
    void ProcessPacket(const std::vector<char>& packet_data)
    {
        if (packet_data.size() < sizeof(PacketHeader))
            return;
            
        const PacketHeader* header = reinterpret_cast<const PacketHeader*>(
            packet_data.data());
        
        auto it = handlers_.find(header->packet_id);
        if (it != handlers_.end())
        {
            it->second(packet_data.data(), packet_data.size());
        }
        else
        {
            std::cout << "Unknown packet ID: " << header->packet_id << std::endl;
        }
    }
    
private:
    std::unordered_map<uint16_t, PacketHandler> handlers_;
};
```
   
`PacketProcessor`는 수신된 완전한 패킷(`vector<char>`)을 받아 헤더의 `packet_id`를 읽고, 미리 등록된 핸들러 함수를 찾아 호출한다.

#### 클래스 개요
`PacketProcessor`는 네트워크 계층에서 올라온 **완성된 패킷을 논리 처리 단계로 전달하는 중간 모듈**이다.
각 `packet_id`에 대응하는 처리 함수를 등록(`RegisterHandler`)해두고,
패킷이 들어오면 `ProcessPacket()`에서 해당 함수를 찾아 실행한다.

이 구조를 사용하면 `switch(packet_id)` 같은 거대한 분기문을 없애고,
새로운 패킷 유형을 추가할 때 단순히 핸들러만 등록하면 되므로 유지보수가 쉬워진다.


### 타입 정의

```cpp
using PacketHandler = std::function<void(const char*, size_t)>;
```

* 각 패킷을 처리할 콜백 함수의 형태를 정의한다.
* 인자는 `const char*`(패킷 데이터)와 `size_t`(패킷 전체 크기)다.
* `std::function`을 사용했기 때문에 람다, 멤버 함수, 전역 함수 등 어떤 형태든 등록 가능하다.

예를 들어 다음처럼 등록할 수 있다:

```cpp
processor.RegisterHandler(1001, [](const char* data, size_t size) {
    const MyPacket* pkt = reinterpret_cast<const MyPacket*>(data);
    // 패킷 처리 로직
});
```

#### RegisterHandler()

```cpp
void RegisterHandler(uint16_t packet_id, PacketHandler handler)
{
    handlers_[packet_id] = handler;
}
```

* `packet_id`별로 처리 함수를 `unordered_map`에 등록한다.
* 동일한 ID를 재등록하면 기존 핸들러가 덮어씌워진다.
* 일반적으로 서버 시작 시점에 모든 패킷 타입을 등록한다.


#### ProcessPacket()

```cpp
void ProcessPacket(const std::vector<char>& packet_data)
{
    if (packet_data.size() < sizeof(PacketHeader))
        return;
        
    const PacketHeader* header = reinterpret_cast<const PacketHeader*>(packet_data.data());
    
    auto it = handlers_.find(header->packet_id);
    if (it != handlers_.end())
    {
        it->second(packet_data.data(), packet_data.size());
    }
    else
    {
        std::cout << "Unknown packet ID: " << header->packet_id << std::endl;
    }
}
```

#### 처리 절차
1. **기본 검증**
   패킷 길이가 헤더 크기보다 작으면 잘못된 데이터이므로 바로 리턴한다.
2. **헤더 해석**
   버퍼의 맨 앞을 `PacketHeader`로 해석해 `packet_id`를 얻는다.
3. **핸들러 검색**
   등록된 핸들러 맵(`handlers_`)에서 해당 ID를 찾는다.
4. **핸들러 실행**
   존재하면 등록된 함수(콜백)를 호출해 처리한다.
   존재하지 않으면 콘솔에 “Unknown packet ID”를 출력한다.

#### 설계적 장점
1. **확장성**
   새 패킷을 추가할 때 코드 수정 없이 핸들러 등록만 하면 된다.

   ```cpp
   processor.RegisterHandler(PKT_LOGIN, HandleLogin);
   processor.RegisterHandler(PKT_CHAT, HandleChat);
   ```
2. **유연성**
   `std::function` 덕분에 멤버 함수, 람다 등 다양한 형태의 콜백을 등록할 수 있다.
3. **유지보수성**
   `switch-case` 방식보다 가독성이 좋고, 각 패킷별 로직이 분리되어 관리가 쉽다.
4. **런타임 교체 가능성**
   필요 시 핸들러를 동적으로 바꿀 수도 있다(테스트, 리로드 등).

#### 요약

| 항목     | 내용                                        |
| ------ | ----------------------------------------- |
| 역할     | 패킷 ID 기반으로 적절한 핸들러를 호출하는 디스패처             |
| 등록 방식  | `RegisterHandler(packet_id, handler)`     |
| 처리 방식  | `ProcessPacket()`이 헤더에서 ID를 읽고, 등록된 함수 실행 |
| 장점     | 구조 단순, 확장 용이, 유지보수성 높음                    |
| 개선 포인트 | 헤더 안전 파싱, 로그 강화, 핸들러 시그니처 확장, 동시성 고려      |
  
정리하면 `PacketProcessor`는 네트워크 수신 스레드가 수집한 패킷을 **논리 계층으로 라우팅하는 핵심 허브 클래스**이며,
핸들러 등록 기반의 구조로 설계되어 확장성과 유지보수성이 뛰어나다.
실제 서비스에 적용할 때는 헤더 검증, 세션 전달, 로깅, 동시성 안정성 등을 추가해 완성도를 높이면 된다.

  
### 9.2.4 고급 세션 클래스 구현

```cpp
class GameSession : public std::enable_shared_from_this<GameSession>
{
public:
    GameSession(tcp::socket socket, SessionManager& manager)
        : socket_(std::move(socket)), manager_(manager)
    {
        InitializePacketHandlers();
        manager_.AddSession(shared_from_this());
    }
    
    ~GameSession()
    {
        manager_.RemoveSession(shared_from_this());
    }
    
    void Start()
    {
        DoRead();
    }
    
private:
    void InitializePacketHandlers()
    {
        processor_.RegisterHandler(PACKET_LOGIN, 
            [this](const char* data, size_t size) { HandleLogin(data, size); });
        processor_.RegisterHandler(PACKET_CHAT,
            [this](const char* data, size_t size) { HandleChat(data, size); });
    }
    
    void DoRead()
    {
        auto self(shared_from_this());
        socket_.async_read_some(
            boost::asio::buffer(receive_buffer_.GetWriteBuffer(), 
                              receive_buffer_.GetWritableSize()),
            [this, self](boost::system::error_code ec, std::size_t length)
            {
                if (!ec)
                {
                    receive_buffer_.AdvanceWritePos(length);
                    ProcessPackets();
                    DoRead();
                }
                else
                {
                    std::cout << "Read error: " << ec.message() << std::endl;
                }
            });
    }
    
    void ProcessPackets()
    {
        std::vector<char> packet_data;
        while (receive_buffer_.ReadPacket(packet_data))
        {
            processor_.ProcessPacket(packet_data);
        }
    }
    
    void HandleLogin(const char* data, size_t size)
    {
        const LoginPacket* packet = reinterpret_cast<const LoginPacket*>(data);
        std::cout << "Login request from: " << packet->user_id << std::endl;
        
        // 로그인 로직 처리
        SendLoginResponse(true);
    }
    
    void HandleChat(const char* data, size_t size)
    {
        const ChatPacket* packet = reinterpret_cast<const ChatPacket*>(data);
        std::cout << "Chat message: " << packet->message << std::endl;
        
        // 채팅 메시지 브로드캐스트
        manager_.BroadcastMessage(packet->message);
    }
    
    void SendLoginResponse(bool success)
    {
        // 로그인 응답 패킷 전송 구현
    }
    
    tcp::socket socket_;
    SessionManager& manager_;
    PacketBuffer receive_buffer_;
    PacketProcessor processor_;
};
```
  
</br>  
  
## 9.3 에러 처리와 예외 상황 대응
게임 서버는 24시간 안정적으로 동작해야 하므로 철저한 에러 처리가 필요하다.

### 9.3.1 에러 코드 정의와 처리

```cpp
enum class ServerError
{
    SUCCESS = 0,
    NETWORK_ERROR = 1000,
    INVALID_PACKET,
    SESSION_NOT_FOUND,
    AUTHENTICATION_FAILED,
    DATABASE_ERROR,
    MEMORY_ALLOCATION_FAILED
};

class ErrorHandler
{
public:
    static void HandleError(ServerError error, const std::string& context)
    {
        switch (error)
        {
        case ServerError::NETWORK_ERROR:
            LogError("Network error in " + context);
            break;
        case ServerError::INVALID_PACKET:
            LogWarning("Invalid packet in " + context);
            break;
        case ServerError::SESSION_NOT_FOUND:
            LogInfo("Session not found in " + context);
            break;
        default:
            LogError("Unknown error in " + context);
            break;
        }
    }
    
private:
    static void LogError(const std::string& message)
    {
        std::cerr << "[ERROR] " << GetCurrentTime() << " " << message << std::endl;
    }
    
    static void LogWarning(const std::string& message)
    {
        std::cout << "[WARN] " << GetCurrentTime() << " " << message << std::endl;
    }
    
    static void LogInfo(const std::string& message)
    {
        std::cout << "[INFO] " << GetCurrentTime() << " " << message << std::endl;
    }
    
    static std::string GetCurrentTime()
    {
        auto now = std::chrono::system_clock::now();
        auto time_t = std::chrono::system_clock::to_time_t(now);
        return std::ctime(&time_t);
    }
};
```

### 9.3.2 타임아웃 처리

```cpp
class TimeoutManager
{
public:
    TimeoutManager(boost::asio::io_context& io_context)
        : timer_(io_context)
    {
    }
    
    void SetTimeout(std::chrono::milliseconds timeout, std::function<void()> callback)
    {
        timer_.expires_after(timeout);
        timer_.async_wait([callback](const boost::system::error_code& ec)
        {
            if (!ec)
            {
                callback();
            }
        });
    }
    
    void Cancel()
    {
        timer_.cancel();
    }
    
private:
    boost::asio::steady_timer timer_;
};

class SessionWithTimeout : public std::enable_shared_from_this<SessionWithTimeout>
{
public:
    SessionWithTimeout(tcp::socket socket)
        : socket_(std::move(socket)), timeout_manager_(socket_.get_executor().context())
    {
    }
    
    void Start()
    {
        SetReadTimeout();
        DoRead();
    }
    
private:
    void SetReadTimeout()
    {
        timeout_manager_.SetTimeout(std::chrono::seconds(30), [this]()
        {
            std::cout << "Session timeout - closing connection" << std::endl;
            socket_.close();
        });
    }
    
    void DoRead()
    {
        auto self(shared_from_this());
        socket_.async_read_some(
            boost::asio::buffer(data_, max_length),
            [this, self](boost::system::error_code ec, std::size_t length)
            {
                timeout_manager_.Cancel(); // 타임아웃 취소
                
                if (!ec)
                {
                    ProcessData(length);
                    SetReadTimeout(); // 새 타임아웃 설정
                    DoRead();
                }
                else
                {
                    std::cout << "Read error: " << ec.message() << std::endl;
                }
            });
    }
    
    void ProcessData(std::size_t length)
    {
        // 데이터 처리
    }
    
    tcp::socket socket_;
    TimeoutManager timeout_manager_;
    enum { max_length = 1024 };
    char data_[max_length];
};
```

### 9.3.3 연결 복구 및 재시도 메커니즘

```cpp
class RobustClient
{
public:
    RobustClient(boost::asio::io_context& io_context, 
                 const std::string& host, const std::string& port)
        : io_context_(io_context), host_(host), port_(port),
          socket_(io_context), timer_(io_context), 
          resolver_(io_context), reconnect_attempts_(0)
    {
    }
    
    void Connect()
    {
        auto self = shared_from_this();
        resolver_.async_resolve(host_, port_,
            [this, self](boost::system::error_code ec, 
                         tcp::resolver::results_type endpoints)
            {
                if (!ec)
                {
                    DoConnect(endpoints);
                }
                else
                {
                    ScheduleReconnect();
                }
            });
    }
    
private:
    void DoConnect(const tcp::resolver::results_type& endpoints)
    {
        auto self = shared_from_this();
        boost::asio::async_connect(socket_, endpoints,
            [this, self](boost::system::error_code ec, tcp::endpoint)
            {
                if (!ec)
                {
                    reconnect_attempts_ = 0;
                    std::cout << "Connected successfully" << std::endl;
                    StartCommunication();
                }
                else
                {
                    ScheduleReconnect();
                }
            });
    }
    
    void ScheduleReconnect()
    {
        if (reconnect_attempts_ >= max_reconnect_attempts_)
        {
            std::cout << "Max reconnection attempts reached" << std::endl;
            return;
        }
        
        ++reconnect_attempts_;
        auto delay = std::chrono::seconds(
            std::min(30, static_cast<int>(std::pow(2, reconnect_attempts_))));
        
        std::cout << "Reconnecting in " << delay.count() << " seconds..." << std::endl;
        
        timer_.expires_after(delay);
        timer_.async_wait([this](boost::system::error_code ec)
        {
            if (!ec)
            {
                Connect();
            }
        });
    }
    
    void StartCommunication()
    {
        // 통신 시작
    }
    
    boost::asio::io_context& io_context_;
    std::string host_;
    std::string port_;
    tcp::socket socket_;
    boost::asio::steady_timer timer_;
    tcp::resolver resolver_;
    int reconnect_attempts_;
    static const int max_reconnect_attempts_ = 5;
};
```
     
일정 시간 동안 클라이언트가 데이터를 보내지 않으면 자동으로 연결을 끊는다.
이를 위해 `TimeoutManager` 클래스로 타이머를 관리하고, `SessionWithTimeout`이 실제 세션 단위에서 이를 사용하는 방식으로 설계되어 있다.
 
#### 전체 구조 개요

```
클라이언트 접속
   ↓
SessionWithTimeout::Start()
   ↓
타임아웃 타이머 설정(SetReadTimeout)
   ↓
비동기 수신 시작(DoRead)
   ↓
(1) 데이터 수신 시 → 타이머 취소 후 재설정
(2) 데이터 미수신 시 → 타임아웃 콜백 호출 → 연결 종료
```

즉, “읽기 대기 상태에서 30초 동안 아무 데이터도 오지 않으면 세션을 닫는다”는 로직이다.
이는 **유휴 연결(Idle Connection)**을 자동으로 정리하기 위한 전형적인 서버 측 방어 패턴이다.


#### `TimeoutManager` 클래스 설명

역할

* Boost.Asio의 `steady_timer`를 감싸서 **특정 시간 후 콜백을 호출하는** 간단한 유틸리티 클래스다.
* `SetTimeout()`으로 타임아웃을 설정하고,
  `Cancel()`로 타이머를 취소할 수 있다.

주요 코드 분석

```cpp
class TimeoutManager
{
public:
    TimeoutManager(boost::asio::io_context& io_context)
        : timer_(io_context)
    {
    }
```

* `steady_timer`는 `io_context`를 기반으로 동작하는 비동기 타이머 객체다.
* 내부적으로 Boost.Asio의 이벤트 루프에 등록되어, 시간이 만료되면 콜백이 호출된다.

```cpp
void SetTimeout(std::chrono::milliseconds timeout, std::function<void()> callback)
{
    timer_.expires_after(timeout);
    timer_.async_wait([callback](const boost::system::error_code& ec)
    {
        if (!ec)
        {
            callback();
        }
    });
}
```

* `expires_after()`로 현재 시점으로부터 지정된 시간 후 만료되도록 설정한다.
* `async_wait()`은 비동기 방식으로 대기한다.
* 타이머가 만료되면 콜백이 실행되며,
  만약 `cancel()`이 먼저 호출되면 `error_code`가 `operation_aborted`로 설정되어 콜백이 실행되지 않는다.


```cpp
void Cancel()
{
    timer_.cancel();
}
```

* 타이머를 취소하면 등록된 콜백은 실행되지 않는다.
* 보통 “데이터를 정상적으로 받았을 때” 기존 타이머를 취소하는 데 사용한다.


#### `SessionWithTimeout` 클래스 설명
이 클래스는 클라이언트 세션 하나를 나타내며, 각 세션에 독립된 소켓(`tcp::socket`)과 `TimeoutManager`를 보유한다.
즉, 연결별로 자체적인 타임아웃 관리가 가능하다.
  

생성자

```cpp
SessionWithTimeout(tcp::socket socket)
    : socket_(std::move(socket)), timeout_manager_(socket_.get_executor().context())
{
}
```

* 소켓을 인자로 받아 소유권을 이동한다.
* 소켓이 사용하는 `io_context`를 그대로 `TimeoutManager`에도 전달해 같은 이벤트 루프 안에서 동작하도록 한다.


Start()

```cpp
void Start()
{
    SetReadTimeout();
    DoRead();
}
```

* 세션을 시작하면서 바로 읽기 타임아웃(30초)을 설정하고,
  비동기 읽기(`DoRead()`)를 시작한다.


SetReadTimeout()

```cpp
void SetReadTimeout()
{
    timeout_manager_.SetTimeout(std::chrono::seconds(30), [this]()
    {
        std::cout << "Session timeout - closing connection" << std::endl;
        socket_.close();
    });
}
```

* 30초 후에도 데이터가 오지 않으면 소켓을 닫는다.
* 이로써 유휴 연결이 자동 종료된다.


DoRead()

```cpp
void DoRead()
{
    auto self(shared_from_this());
    socket_.async_read_some(
        boost::asio::buffer(data_, max_length),
        [this, self](boost::system::error_code ec, std::size_t length)
        {
            timeout_manager_.Cancel(); // 타임아웃 취소

            if (!ec)
            {
                ProcessData(length);
                SetReadTimeout(); // 새 타임아웃 설정
                DoRead();
            }
            else
            {
                std::cout << "Read error: " << ec.message() << std::endl;
            }
        });
}
```

#### 동작 순서

1. `async_read_some()`으로 비동기 읽기를 시작한다.
   Boost.Asio는 데이터가 수신되면 콜백을 호출한다.
2. 콜백이 실행되면 먼저 타이머를 취소한다(`timeout_manager_.Cancel()`).

   * 이유: 데이터를 정상적으로 받았으므로 “30초 안에 읽지 못했다”는 상황이 더 이상 유효하지 않기 때문이다.
3. `ec`가 성공이면:

   * 데이터를 처리(`ProcessData`)한 후
   * 새로운 30초 타이머를 재설정(`SetReadTimeout()`)하고
   * 다음 읽기를 재개(`DoRead()`)한다.
4. `ec`가 에러면 로그를 남기고 세션을 종료한다.


#### 동작 예시 흐름

| 시점   | 동작           | 설명                   |
| ---- | ------------ | -------------------- |
| T=0  | `Start()` 호출 | 읽기 시작 + 30초 타임아웃 등록  |
| T=5  | 데이터 수신       | 타임아웃 취소 후 새로 30초 재설정 |
| T=10 | 다음 데이터 수신    | 다시 취소 및 재설정          |
| T=40 | 아무 데이터 없음    | 타임아웃 만료 → 소켓 닫힘      |

  
#### 설계적 장점

1. **유휴 연결 자동 종료**
   장시간 아무 패킷도 보내지 않는 클라이언트를 정리하여 리소스 낭비 방지.
2. **비동기 타이머 사용**
   I/O 스레드 내에서 자연스럽게 동작하므로 추가 스레드 불필요.
3. **모듈화된 구조**
   `TimeoutManager`를 독립 클래스로 분리해 재사용이 용이하다.
4. **안정적 취소 메커니즘**
   타이머를 취소하면 콜백이 안전하게 무시되므로 중복 종료 문제 없음.


#### 주의 및 개선 포인트

1. **`shared_from_this()` 사용 주의**
   세션이 `std::enable_shared_from_this`를 상속받으므로, 객체 수명은 `shared_ptr`로 관리되어야 한다.
   즉, 세션 생성 시 반드시 `std::make_shared<SessionWithTimeout>()`로 생성해야 한다.

2. **타임아웃 중복 등록 방지**
   `SetReadTimeout()` 호출 전에 기존 타이머를 취소하지 않아도 `steady_timer`는 `expires_after()`로 새 만료 시각을 덮어쓴다.
   하지만 논리적으로 “이전 타이머를 먼저 취소 후 새로 설정”하는 게 명확하므로, 개선 시 `Cancel()`을 호출하는 것이 안전하다.

3. **에러 처리 고도화**
   단순히 `std::cout`만 출력하는 대신 로그 시스템이나 세션 종료 로직을 명확히 구현해야 한다.

4. **다른 이벤트와의 타임아웃 통합**
   읽기뿐 아니라 “쓰기 지연”, “핸드셰이크 응답 없음” 등의 타임아웃도 유사 구조로 확장 가능하다.

5. **TLS/SSL 세션에서도 동일 적용 가능**
   `socket_` 대신 `boost::asio::ssl::stream<tcp::socket>`을 사용해도 같은 방식으로 타임아웃 관리 가능하다.


#### 요약

| 항목       | 설명                                         |
| -------- | ------------------------------------------ |
| 클래스      | `TimeoutManager`, `SessionWithTimeout`     |
| 목적       | 읽기 타임아웃 관리 및 자동 연결 종료                      |
| 핵심 메커니즘  | `steady_timer` + `async_wait`              |
| 타임아웃 동작  | 데이터 미수신 시 지정 시간 후 소켓 닫기                    |
| 데이터 수신 시 | 타임아웃 취소 후 재설정                              |
| 장점       | 유휴 세션 정리, 자원 누수 방지, 모듈화 용이                 |
| 주의점      | 수명 관리(`shared_from_this`), 예외 처리, 로그 강화 필요 |

  
</br>  

## 9.4 성능 최적화 기법
게임 서버의 성능을 극대화하기 위한 다양한 최적화 기법을 살펴봅니다.

### 9.4.1 커스텀 메모리 할당자

```cpp
class PoolAllocator
{
public:
    PoolAllocator(size_t block_size, size_t block_count)
        : block_size_(block_size), block_count_(block_count)
    {
        pool_ = new char[block_size_ * block_count_];
        for (size_t i = 0; i < block_count_; ++i)
        {
            free_blocks_.push(pool_ + i * block_size_);
        }
    }
    
    ~PoolAllocator()
    {
        delete[] pool_;
    }
    
    void* Allocate()
    {
        std::lock_guard<std::mutex> lock(mutex_);
        if (free_blocks_.empty())
            return nullptr;
            
        void* block = free_blocks_.top();
        free_blocks_.pop();
        return block;
    }
    
    void Deallocate(void* ptr)
    {
        std::lock_guard<std::mutex> lock(mutex_);
        free_blocks_.push(static_cast<char*>(ptr));
    }
    
private:
    char* pool_;
    size_t block_size_;
    size_t block_count_;
    std::stack<char*> free_blocks_;
    std::mutex mutex_;
};

// Boost.Asio 핸들러에서 사용할 커스텀 할당자
template<typename Handler>
class CustomAllocHandler
{
public:
    CustomAllocHandler(PoolAllocator& allocator, Handler handler)
        : allocator_(allocator), handler_(handler)
    {
    }
    
    template<typename... Args>
    void operator()(Args&&... args)
    {
        handler_(std::forward<Args>(args)...);
    }
    
    friend void* asio_handler_allocate(std::size_t size, 
                                      CustomAllocHandler<Handler>* this_handler)
    {
        return this_handler->allocator_.Allocate();
    }
    
    friend void asio_handler_deallocate(void* pointer, std::size_t /*size*/,
                                       CustomAllocHandler<Handler>* this_handler)
    {
        this_handler->allocator_.Deallocate(pointer);
    }
    
private:
    PoolAllocator& allocator_;
    Handler handler_;
};

template<typename Handler>
auto MakeCustomAllocHandler(PoolAllocator& allocator, Handler handler)
{
    return CustomAllocHandler<Handler>(allocator, handler);
}
```
   
이 코드는 **Boost.Asio 환경에서 동적 메모리 할당 비용을 줄이기 위해 커스텀 메모리 풀을 사용하는 예시**다.
즉, 비동기 핸들러(콜백)가 실행될 때마다 `new`/`delete`를 반복하지 않고,
**미리 할당된 메모리 블록(pool)**을 재사용하도록 설계된 것이다.

이 방식은 서버 성능 최적화에서 자주 쓰이며, 특히 Asio의 비동기 I/O에서는 **작은 객체를 매우 자주 할당/해제**하므로 큰 효율 향상을 얻을 수 있다.

#### 전체 구조 요약
구조를 단순히 정리하면 다음과 같다:

| 클래스                        | 역할                                                  |
| -------------------------- | --------------------------------------------------- |
| `PoolAllocator`            | 고정 크기 메모리 블록을 미리 만들어놓고, 할당/반납을 빠르게 수행               |
| `CustomAllocHandler`       | Boost.Asio에서 사용하는 핸들러(콜백)에 대해, 메모리 할당을 풀에서 수행하도록 연결 |
| `MakeCustomAllocHandler()` | 사용 편의를 위한 헬퍼 함수                                     |

결국, Boost.Asio 내부에서 핸들러를 위해 호출하는 `asio_handler_allocate()` / `asio_handler_deallocate()` 함수를 오버라이드해서
**사용자 정의 풀에서 메모리를 가져오도록 한 것**이 핵심이다.

#### `PoolAllocator` 클래스 상세 분석

생성자

```cpp
PoolAllocator(size_t block_size, size_t block_count)
    : block_size_(block_size), block_count_(block_count)
{
    pool_ = new char[block_size_ * block_count_];
    for (size_t i = 0; i < block_count_; ++i)
    {
        free_blocks_.push(pool_ + i * block_size_);
    }
}
```

* 한 번에 `block_count_`개의 고정 크기 블록을 힙에서 할당한다.
  예: `block_size = 256`, `block_count = 1024`라면 총 256KB 풀 생성.
* 각 블록의 시작 주소를 `stack<char*> free_blocks_`에 저장한다.
* 즉, **“빈 블록 스택”** 구조를 만든다.
* 이후 `Allocate()`를 호출하면 여기서 pop, `Deallocate()`를 호출하면 다시 push 한다.

  
Allocate()

```cpp
void* Allocate()
{
    std::lock_guard<std::mutex> lock(mutex_);
    if (free_blocks_.empty())
        return nullptr;
        
    void* block = free_blocks_.top();
    free_blocks_.pop();
    return block;
}
```

* free list에서 하나 꺼내 반환한다.
* 남은 블록이 없으면 `nullptr`을 반환한다(즉, 풀 고갈 상태).
* `mutex_`는 다중 스레드 환경에서 안전성을 보장하기 위해 사용된다.
  

Deallocate()

```cpp
void Deallocate(void* ptr)
{
    std::lock_guard<std::mutex> lock(mutex_);
    free_blocks_.push(static_cast<char*>(ptr));
}
```

* 다시 반환받은 메모리를 스택에 넣어 재사용할 수 있게 한다.
  
  
소멸자

```cpp
~PoolAllocator()
{
    delete[] pool_;
}
```

* 프로그램 종료 시 전체 풀 메모리를 해제한다.
  
  
✅ 요약: PoolAllocator의 동작 방식

```
초기화:  [B1][B2][B3][B4] ... [Bn]   ← free_blocks_에 전부 push
할당   :  pop() → [B1] 사용 중
반납   :  push(B1) → 다시 사용 가능
```

이런 식으로 힙 단편화를 막고, 매우 빠른 고정 크기 메모리 관리가 가능하다.


#### Boost.Asio와의 연동 — `CustomAllocHandler`
Boost.Asio는 내부적으로 핸들러 호출 시 `asio_handler_allocate()` / `asio_handler_deallocate()` 훅을 호출한다.
이 함수들을 “friend”로 정의함으로써, 핸들러마다 커스텀 메모리 할당을 제어할 수 있다.
  

클래스 정의

```cpp
template<typename Handler>
class CustomAllocHandler
{
public:
    CustomAllocHandler(PoolAllocator& allocator, Handler handler)
        : allocator_(allocator), handler_(handler)
    {
    }

    template<typename... Args>
    void operator()(Args&&... args)
    {
        handler_(std::forward<Args>(args)...);
    }
```

* `CustomAllocHandler`는 **실제 사용자 핸들러(`handler_`)를 감싸는 래퍼**다.
* Asio는 핸들러 실행 시 이 객체를 통해 호출한다.
* `operator()`가 호출되면 내부의 원래 핸들러를 실행한다.
* `PoolAllocator` 참조(`allocator_`)를 보관하고 있어서 메모리 할당에 사용할 수 있다.

  
asio_handler_allocate / asio_handler_deallocate

```cpp
friend void* asio_handler_allocate(std::size_t size, 
                                  CustomAllocHandler<Handler>* this_handler)
{
    return this_handler->allocator_.Allocate();
}

friend void asio_handler_deallocate(void* pointer, std::size_t /*size*/,
                                   CustomAllocHandler<Handler>* this_handler)
{
    this_handler->allocator_.Deallocate(pointer);
}
```

* Boost.Asio는 내부에서 “핸들러용 메모리를 할당해야 할 때” 이 함수를 호출한다.
* 즉, 핸들러당 필요한 메모리를 `operator new`로 할당하지 않고,
  **커스텀 풀에서 블록을 꺼내 쓰도록 오버라이드한 것**이다.
* `size`는 무시하고, 항상 같은 크기의 블록을 반환한다.
* 해제 시에는 다시 `Deallocate()`로 돌려보낸다.
  
  
MakeCustomAllocHandler()

```cpp
template<typename Handler>
auto MakeCustomAllocHandler(PoolAllocator& allocator, Handler handler)
{
    return CustomAllocHandler<Handler>(allocator, handler);
}
```

* 헬퍼 함수로, 매번 템플릿 인자를 명시하지 않고도 간편하게 래퍼 객체를 생성할 수 있게 한다.
* 사용 예:

  ```cpp
  socket_.async_read_some(
      boost::asio::buffer(data_),
      MakeCustomAllocHandler(allocator_, [this](boost::system::error_code ec, std::size_t len) {
          // 핸들러 로직
      })
  );
  ```

  
#### 전체 동작 흐름
1. 서버는 `PoolAllocator`를 생성해 일정 개수의 블록을 준비한다.
2. `async_read_some` 등에서 핸들러를 등록할 때,
   `MakeCustomAllocHandler()`로 감싸서 등록한다.
3. Asio 내부에서 핸들러 호출 시 메모리가 필요하면
   `asio_handler_allocate()` → `PoolAllocator::Allocate()`가 호출되어 블록을 할당한다.
4. 핸들러 실행 후 Asio가 핸들러 객체를 해제하면
   `asio_handler_deallocate()` → `PoolAllocator::Deallocate()`가 호출되어 블록을 반환한다.

결국, **Boost.Asio가 사용하는 핸들러 메모리를 모두 미리 준비된 풀에서 재사용**하는 구조가 완성된다.


#### 장점

| 항목                 | 설명                                               |
| ------------------ | ------------------------------------------------ |
| **성능 향상**          | `new`/`delete` 호출 오버헤드와 힙 단편화를 방지한다.             |
| **예측 가능한 메모리 사용량** | 블록 개수와 크기를 고정시켜 메모리 사용 한계를 명확히 한다.               |
| **메모리 단편화 감소**     | 자주 할당/해제되는 작은 객체들을 고정 크기 블록으로 관리.                |
| **Asio와 자연스러운 통합** | `asio_handler_allocate` 훅을 이용해 프레임워크에 깔끔하게 통합된다. |

  
#### 주의점 및 개선 방향

1. **풀 고갈 처리**
   현재는 `Allocate()` 실패 시 `nullptr`을 반환하는데,
   실제 서비스에서는 `nullptr`을 그대로 반환하면 크래시 위험이 있다.
   → 대안: 예외 던지기, 대기, 또는 임시 `new`로 fallback.

2. **블록 크기 가변성 부족**
   모든 블록이 동일 크기이므로, 큰 핸들러나 다른 객체를 담기 어려움.
   → 여러 크기의 풀을 병행하거나, size 기반으로 다른 풀 선택.

3. **멀티스레드 성능**
   `std::mutex`로 보호하므로 다중 스레드 환경에서는 경합이 생길 수 있다.
   → thread-local 풀(`thread_local PoolAllocator`)로 나누면 경합을 줄일 수 있다.

4. **파괴 시점**
   Asio가 핸들러를 해제하는 시점은 이벤트 루프에 따라 다르므로,
   풀이 먼저 소멸하면 잘못된 포인터가 남을 수 있다.
   → 풀의 수명을 `io_context`보다 길게 유지해야 한다.
  

#### 사용 예시

```cpp
PoolAllocator allocator(256, 1024); // 256바이트 블록 1024개 준비

boost::asio::io_context io;
tcp::socket socket(io);

socket.async_read_some(
    boost::asio::buffer(data),
    MakeCustomAllocHandler(allocator, 
        [&](const boost::system::error_code& ec, std::size_t bytes)
        {
            if (!ec)
                std::cout << "Read " << bytes << " bytes\n";
        })
);

io.run();
```

이 경우, Boost.Asio는 내부 핸들러 객체의 메모리를 `allocator` 풀에서 가져오게 된다.
따라서 read 요청이 매우 빈번하게 발생해도 `new/delete`를 거의 사용하지 않는다.


#### 요약

| 항목     | 내용                                               |
| ------ | ------------------------------------------------ |
| 핵심 목적  | Boost.Asio 핸들러의 메모리 할당 오버헤드 제거                   |
| 주요 클래스 | `PoolAllocator`, `CustomAllocHandler`            |
| 동작 방식  | 미리 만든 고정 크기 블록 풀에서 핸들러 메모리 제공                    |
| 장점     | 빠른 할당/해제, 단편화 방지, 예측 가능한 메모리 사용                  |
| 주의점    | 풀 고갈 처리, 블록 크기 제한, 멀티스레드 경합                      |
| 사용 패턴  | `MakeCustomAllocHandler(allocator, handler)`로 등록 |

  
핸들러당 `new/delete` 대신 풀을 사용함으로써, **지연 시간 단축과 메모리 안정성 향상**을 동시에 달성할 수 있다.

  
### 9.4.2 객체 풀링

```cpp
template<typename T>
class ObjectPool
{
public:
    template<typename... Args>
    std::shared_ptr<T> Acquire(Args&&... args)
    {
        std::lock_guard<std::mutex> lock(mutex_);
        
        if (pool_.empty())
        {
            return std::shared_ptr<T>(new T(std::forward<Args>(args)...),
                [this](T* obj) { this->Return(obj); });
        }
        
        auto obj = pool_.top();
        pool_.pop();
        return std::shared_ptr<T>(obj, [this](T* obj) { this->Return(obj); });
    }
    
private:
    void Return(T* obj)
    {
        std::lock_guard<std::mutex> lock(mutex_);
        pool_.push(obj);
    }
    
    std::stack<T*> pool_;
    std::mutex mutex_;
};

// 사용 예제
class GameSessionPool
{
public:
    std::shared_ptr<GameSession> CreateSession(tcp::socket socket)
    {
        return session_pool_.Acquire(std::move(socket));
    }
    
private:
    ObjectPool<GameSession> session_pool_;
};
```
  

### 9.4.3 논블로킹 큐를 활용한 스레드 간 통신

```cpp
template<typename T>
class LockFreeQueue
{
public:
    LockFreeQueue() : head_(new Node), tail_(head_.load())
    {
    }
    
    void Enqueue(T item)
    {
        Node* new_node = new Node;
        Node* prev_tail = tail_.exchange(new_node);
        prev_tail->data = std::move(item);
        prev_tail->next = new_node;
    }
    
    bool Dequeue(T& result)
    {
        Node* head = head_.load();
        Node* next = head->next;
        
        if (next == nullptr)
            return false;
            
        result = std::move(next->data);
        head_.store(next);
        delete head;
        return true;
    }
    
private:
    struct Node
    {
        std::atomic<Node*> next{nullptr};
        T data;
    };
    
    std::atomic<Node*> head_;
    std::atomic<Node*> tail_;
};
```
  


## 정리
이번 장에서는 Boost.Asio를 활용한 고급 비동기 기법들을 살펴보았습니다. 주요 내용을 요약하면:

1. **std::shared_ptr을 활용한 세션 관리**: 자동 메모리 관리와 안전한 세션 생명주기 관리
2. **패킷 처리와 프로토콜 설계**: 효율적인 패킷 버퍼링과 처리 메커니즘
3. **에러 처리와 예외 상황 대응**: 견고한 서버를 위한 에러 처리와 타임아웃 관리
4. **성능 최적화 기법**: 메모리 풀링, 배치 처리, 객체 재사용을 통한 성능 향상

이러한 기법들은 실제 게임 서버 개발에서 필수적인 요소들이며, 안정적이고 고성능인 서버를 구축하는 데 중요한 역할을 한다. 다음 장에서는 UDP 프로그래밍을 통해 실시간 게임에서 중요한 저지연 통신을 구현하는 방법을 학습하겠다.   
  