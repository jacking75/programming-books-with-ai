# Modern C++로 안전하고 우아한 프로그래밍  

저자: 최흥배, Claude AI   
    
권장 개발 환경
- **IDE**: Visual Studio 2022 (Community 이상)
- **컴파일러**: MSVC v143 (C++20 지원)
- **OS**: Windows 10 이상

-----  
  
# Chapter 18: 성능 벤치마킹과 최적화
프로그램이 올바르게 동작하는 것도 중요하지만, 얼마나 빠르고 효율적으로 동작하는지도 매우 중요하다. 이 장에서는 C++ 프로그램의 성능을 측정하고 최적화하는 방법을 배운다. 성능 최적화를 하기 전에 먼저 측정해야 한다는 것이 핵심이다. 추측으로 최적화하면 실제로는 성능이 저하될 수도 있기 때문이다.
  


## 18.1 마이크로 벤치마킹 기법
마이크로 벤치마킹은 아주 작은 코드 조각의 성능을 측정하는 기법이다. 함수 하나, 루프 하나, 또는 연산 하나의 성능을 정확하게 측정한다.

먼저 간단한 벤치마킹 프레임워크를 만들어보자.

```cpp
// benchmarking/timer.hpp
#ifndef BENCHMARKING_TIMER_HPP
#define BENCHMARKING_TIMER_HPP

#include <chrono>
#include <string>
#include <iostream>
#include <iomanip>
#include <vector>
#include <algorithm>
#include <numeric>
#include <cmath>

namespace benchmarking {
    // 정밀한 시간 측정을 위한 스톱워치 클래스
    class StopWatch {
    private:
        using clock = std::chrono::high_resolution_clock;
        using ns = std::chrono::nanoseconds;

        clock::time_point start_time_;
        bool running_;

    public:
        StopWatch() : running_(false) {}

        void start() {
            start_time_ = clock::now();
            running_ = true;
        }

        void stop() {
            running_ = false;
        }

        // 경과 시간을 나노초 단위로 반환한다
        long long elapsed_ns() const {
            if (!running_) {
                return 0;
            }
            auto end = clock::now();
            return std::chrono::duration_cast<ns>(end - start_time_).count();
        }

        // 경과 시간을 마이크로초 단위로 반환한다
        double elapsed_us() const {
            return static_cast<double>(elapsed_ns()) / 1000.0;
        }

        // 경과 시간을 밀리초 단위로 반환한다
        double elapsed_ms() const {
            return static_cast<double>(elapsed_ns()) / 1000000.0;
        }

        // 경과 시간을 초 단위로 반환한다
        double elapsed_s() const {
            return static_cast<double>(elapsed_ns()) / 1000000000.0;
        }

        void reset() {
            running_ = false;
        }
    };

    // 벤치마크 결과를 저장하는 클래스
    class BenchmarkResult {
    private:
        std::vector<long long> times_;  // 나노초 단위
        std::string name_;

    public:
        explicit BenchmarkResult(const std::string& name) : name_(name) {}

        void add_time(long long ns) {
            times_.push_back(ns);
        }

        // 최소 실행 시간
        long long min_ns() const {
            return *std::min_element(times_.begin(), times_.end());
        }

        // 최대 실행 시간
        long long max_ns() const {
            return *std::max_element(times_.begin(), times_.end());
        }

        // 평균 실행 시간
        double mean_ns() const {
            if (times_.empty()) return 0;
            long long sum = std::accumulate(times_.begin(), times_.end(), 0LL);
            return static_cast<double>(sum) / times_.size();
        }

        // 표준 편차
        double stddev_ns() const {
            if (times_.size() < 2) return 0;
            double mean = mean_ns();
            double variance = 0;
            for (auto t : times_) {
                double diff = t - mean;
                variance += diff * diff;
            }
            variance /= times_.size();
            return std::sqrt(variance);
        }

        // 중앙값
        long long median_ns() const {
            if (times_.empty()) return 0;
            std::vector<long long> sorted = times_;
            std::sort(sorted.begin(), sorted.end());
            return sorted[sorted.size() / 2];
        }

        size_t iteration_count() const {
            return times_.size();
        }

        // 결과 출력
        void print() const {
            std::cout << "\n=== Benchmark Results: " << name_ << " ===\n";
            std::cout << std::fixed << std::setprecision(2);
            std::cout << "Iterations:   " << iteration_count() << "\n";
            std::cout << "Min:          " << min_ns() << " ns ("
                     << min_ns() / 1000.0 << " us)\n";
            std::cout << "Max:          " << max_ns() << " ns ("
                     << max_ns() / 1000.0 << " us)\n";
            std::cout << "Mean:         " << mean_ns() << " ns ("
                     << mean_ns() / 1000.0 << " us)\n";
            std::cout << "Median:       " << median_ns() << " ns ("
                     << median_ns() / 1000.0 << " us)\n";
            std::cout << "Std Dev:      " << stddev_ns() << " ns ("
                     << stddev_ns() / 1000.0 << " us)\n";
        }
    };

    // 벤치마킹 함수
    template<typename Function>
    BenchmarkResult benchmark(
        const std::string& name,
        Function func,
        size_t iterations = 1000,
        size_t warmup_iterations = 100
    ) {
        BenchmarkResult result(name);

        // 워밍업 실행 (캐시 워밍, JIT 컴파일 등)
        for (size_t i = 0; i < warmup_iterations; ++i) {
            func();
        }

        // 실제 벤치마크 실행
        for (size_t i = 0; i < iterations; ++i) {
            StopWatch timer;
            timer.start();
            func();
            long long elapsed = timer.elapsed_ns();
            result.add_time(elapsed);
        }

        return result;
    }
}

#endif // BENCHMARKING_TIMER_HPP
```

이 코드의 목적은 함수의 실행 시간을 정확하게 측정하는 것이다. 설명하자면 먼저 `StopWatch` 클래스는 `high_resolution_clock`을 사용하여 나노초 단위의 정밀한 시간을 측정한다. `BenchmarkResult` 클래스는 여러 번 반복 실행한 결과를 수집하고 통계를 계산한다. 특히 최소, 최대, 평균, 중앙값, 표준 편차를 계산하여 결과의 안정성을 판단할 수 있다.

워밍업 반복(warmup iterations)은 매우 중요하다. 첫 번째 실행은 보통 느리기 때문에 정확한 측정을 위해서는 워밍업이 필수다.

이제 실제로 벤치마킹을 해보자.

```cpp
// example_benchmark.cpp
#include "benchmarking/timer.hpp"
#include <vector>
#include <algorithm>
#include <numeric>

// 성능 비교할 함수들
// 방법 1: 전통적인 for 루프
std::vector<int> sum_traditional(const std::vector<int>& vec) {
    std::vector<int> result(vec.size());
    for (size_t i = 0; i < vec.size(); ++i) {
        result[i] = vec[i] * 2;
    }
    return result;
}

// 방법 2: std::transform 사용
std::vector<int> sum_transform(const std::vector<int>& vec) {
    std::vector<int> result(vec.size());
    std::transform(vec.begin(), vec.end(), result.begin(),
                  [](int x) { return x * 2; });
    return result;
}

// 방법 3: 범위 기반 for 루프
std::vector<int> sum_range_based(const std::vector<int>& vec) {
    std::vector<int> result;
    result.reserve(vec.size());
    for (auto v : vec) {
        result.push_back(v * 2);
    }
    return result;
}

int main() {
    using namespace benchmarking;

    // 테스트 데이터 준비
    std::vector<int> data(10000);
    std::iota(data.begin(), data.end(), 0);

    // 벤치마크 1: 전통적인 for 루프
    auto result1 = benchmark(
        "Traditional for loop",
        [&data]() {
            volatile auto r = sum_traditional(data);
            (void)r;  // 컴파일러가 최적화하지 않도록
        },
        1000,
        100
    );
    result1.print();

    // 벤치마크 2: std::transform
    auto result2 = benchmark(
        "std::transform",
        [&data]() {
            volatile auto r = sum_transform(data);
            (void)r;
        },
        1000,
        100
    );
    result2.print();

    // 벤치마크 3: 범위 기반 for 루프
    auto result3 = benchmark(
        "Range-based for loop",
        [&data]() {
            volatile auto r = sum_range_based(data);
            (void)r;
        },
        1000,
        100
    );
    result3.print();

    return 0;
}
```

마이크로 벤치마킹을 할 때 주의할 점이 몇 가지 있다. 먼저 컴파일러가 죽은 코드(dead code) 제거 최적화를 하지 않도록 `volatile`을 사용한다. 두 번째로 워밍업 반복을 충분히 하여 캐시 상태를 안정화한다. 세 번째로 표준 편차를 확인하여 결과의 일관성을 검증한다. 네 번째로 시스템 부하가 적을 때 벤치마크를 실행한다.

더 정교한 벤치마킹을 위해서는 구글의 Google Benchmark 라이브러리를 사용할 수 있다.

```cpp
// benchmark_with_google.cpp
#include <benchmark/benchmark.h>
#include <vector>
#include <algorithm>
#include <numeric>

static std::vector<int> data(10000);

// Google Benchmark를 사용한 벤치마킹
static void BM_TraditionalLoop(benchmark::State& state) {
    for (auto _ : state) {
        std::vector<int> result(data.size());
        for (size_t i = 0; i < data.size(); ++i) {
            result[i] = data[i] * 2;
        }
        benchmark::DoNotOptimize(result);
    }
}
BENCHMARK(BM_TraditionalLoop);

static void BM_StdTransform(benchmark::State& state) {
    for (auto _ : state) {
        std::vector<int> result(data.size());
        std::transform(data.begin(), data.end(), result.begin(),
                      [](int x) { return x * 2; });
        benchmark::DoNotOptimize(result);
    }
}
BENCHMARK(BM_StdTransform);

static void BM_RangeBasedFor(benchmark::State& state) {
    for (auto _ : state) {
        std::vector<int> result;
        result.reserve(data.size());
        for (auto v : data) {
            result.push_back(v * 2);
        }
        benchmark::DoNotOptimize(result);
    }
}
BENCHMARK(BM_RangeBasedFor);

// 매개변수화된 벤치마크
static void BM_VectorSize(benchmark::State& state) {
    std::vector<int> test_data(state.range(0));
    std::iota(test_data.begin(), test_data.end(), 0);

    for (auto _ : state) {
        std::vector<int> result(test_data.size());
        std::transform(test_data.begin(), test_data.end(), result.begin(),
                      [](int x) { return x * 2; });
        benchmark::DoNotOptimize(result);
    }
    state.SetComplexityN(state.range(0));
}
BENCHMARK(BM_VectorSize)->RangeMultiplier(2)->Range(1 << 10, 1 << 20);

int main(int argc, char** argv) {
    // 데이터 초기화
    std::iota(data.begin(), data.end(), 0);

    benchmark::Initialize(&argc, argv);
    benchmark::RunSpecifiedBenchmarks();
    return 0;
}
```
  


## 18.2 메모리 사용량 최적화
메모리 효율성은 성능에 큰 영향을 미친다. 불필요한 메모리 할당, 캐시 미스, 메모리 단편화 등을 최소화해야 한다.

먼저 메모리 할당 패턴을 최적화하는 방법을 보자.

```cpp
// memory_optimization.cpp
#include <vector>
#include <string>
#include <memory>
#include <iostream>
#include <chrono>

// 메모리 할당을 측정하는 유틸리티
class AllocationTracker {
private:
    static size_t allocation_count_;
    static size_t total_allocated_;

public:
    static void* allocate(size_t size) {
        allocation_count_++;
        total_allocated_ += size;
        return malloc(size);
    }

    static void deallocate(void* ptr) {
        free(ptr);
    }

    static void reset() {
        allocation_count_ = 0;
        total_allocated_ = 0;
    }

    static size_t get_allocation_count() {
        return allocation_count_;
    }

    static size_t get_total_allocated() {
        return total_allocated_;
    }

    static void print_stats() {
        std::cout << "Allocations: " << allocation_count_ << "\n";
        std::cout << "Total allocated: " << total_allocated_ << " bytes\n";
    }
};

size_t AllocationTracker::allocation_count_ = 0;
size_t AllocationTracker::total_allocated_ = 0;

// 비효율적인 방법: 루프에서 반복 할당
std::string build_string_inefficient(int count) {
    std::string result;
    for (int i = 0; i < count; ++i) {
        result += "x";  // 매번 재할당 발생
    }
    return result;
}

// 효율적인 방법 1: reserve 사용
std::string build_string_reserved(int count) {
    std::string result;
    result.reserve(count);  // 미리 메모리 할당
    for (int i = 0; i < count; ++i) {
        result += "x";
    }
    return result;
}

// 효율적인 방법 2: 벡터 사용 후 join
std::string build_string_vector(int count) {
    std::vector<char> chars;
    chars.reserve(count);
    for (int i = 0; i < count; ++i) {
        chars.push_back('x');
    }
    return std::string(chars.begin(), chars.end());
}

// 벡터 메모리 최적화 예제
class DataContainer {
private:
    std::vector<int> data_;

public:
    // 효율적이지 않은 방법: 여러 번의 push_back
    static DataContainer build_inefficient(int size) {
        DataContainer container;
        for (int i = 0; i < size; ++i) {
            container.data_.push_back(i);  // 재할당 발생 가능
        }
        return container;
    }

    // 효율적인 방법: reserve 사용
    static DataContainer build_efficient(int size) {
        DataContainer container;
        container.data_.reserve(size);  // 미리 메모리 할당
        for (int i = 0; i < size; ++i) {
            container.data_.push_back(i);
        }
        return container;
    }

    // 효율적인 방법 2: 초기 크기 지정
    static DataContainer build_preallocated(int size) {
        DataContainer container;
        container.data_.resize(size);  // 미리 크기 설정
        for (int i = 0; i < size; ++i) {
            container.data_[i] = i;
        }
        return container;
    }

    size_t memory_usage() const {
        return data_.capacity() * sizeof(int);
    }

    size_t data_size() const {
        return data_.size() * sizeof(int);
    }
};

int main() {
    // 문자열 빌드 성능 비교
    std::cout << "=== String Building Comparison ===\n";

    const int STRING_SIZE = 10000;

    std::cout << "\nInefficient (no reserve):\n";
    AllocationTracker::reset();
    auto s1 = build_string_inefficient(STRING_SIZE);
    AllocationTracker::print_stats();

    std::cout << "\nEfficient (with reserve):\n";
    AllocationTracker::reset();
    auto s2 = build_string_reserved(STRING_SIZE);
    AllocationTracker::print_stats();

    std::cout << "\nVector approach:\n";
    AllocationTracker::reset();
    auto s3 = build_string_vector(STRING_SIZE);
    AllocationTracker::print_stats();

    // 벡터 메모리 효율성 비교
    std::cout << "\n\n=== Vector Memory Efficiency ===\n";

    const int VECTOR_SIZE = 100000;

    auto c1 = DataContainer::build_inefficient(VECTOR_SIZE);
    std::cout << "Inefficient method:\n";
    std::cout << "  Data size: " << c1.data_size() << " bytes\n";
    std::cout << "  Allocated: " << c1.memory_usage() << " bytes\n";

    auto c2 = DataContainer::build_efficient(VECTOR_SIZE);
    std::cout << "Efficient method (reserve):\n";
    std::cout << "  Data size: " << c2.data_size() << " bytes\n";
    std::cout << "  Allocated: " << c2.memory_usage() << " bytes\n";

    auto c3 = DataContainer::build_preallocated(VECTOR_SIZE);
    std::cout << "Preallocated method:\n";
    std::cout << "  Data size: " << c3.data_size() << " bytes\n";
    std::cout << "  Allocated: " << c3.memory_usage() << " bytes\n";

    return 0;
}
```

메모리 접근 패턴도 성능에 큰 영향을 미친다. 배열의 구조(AOS, Array of Structs)와 구조의 배열(SoA, Structure of Arrays)을 비교해보자.

```cpp
// cache_optimization.cpp
#include <vector>
#include <algorithm>
#include <chrono>
#include <iostream>
#include <iomanip>

// 메모리 레이아웃 최적화 예제

// 방법 1: 구조의 배열 (Array of Structs)
struct Particle_AOS {
    float x, y, z;      // 위치 (12 bytes)
    float vx, vy, vz;   // 속도 (12 bytes)
    float lifetime;     // 생명 시간 (4 bytes)
    // 패딩 (4 bytes)
    // 총 32 bytes per particle
};

// 방법 2: 배열의 구조 (Structure of Arrays)
struct ParticleBuffer_SoA {
    std::vector<float> x, y, z;
    std::vector<float> vx, vy, vz;
    std::vector<float> lifetime;

    void resize(size_t count) {
        x.resize(count);
        y.resize(count);
        z.resize(count);
        vx.resize(count);
        vy.resize(count);
        vz.resize(count);
        lifetime.resize(count);
    }

    size_t size() const { return x.size(); }
};

// AOS를 사용한 업데이트
void update_particles_AOS(std::vector<Particle_AOS>& particles, float dt) {
    for (auto& p : particles) {
        p.x += p.vx * dt;
        p.y += p.vy * dt;
        p.z += p.vz * dt;
        p.lifetime -= dt;
    }
}

// SoA를 사용한 업데이트
void update_particles_SoA(ParticleBuffer_SoA& particles, float dt) {
    for (size_t i = 0; i < particles.size(); ++i) {
        particles.x[i] += particles.vx[i] * dt;
        particles.y[i] += particles.vy[i] * dt;
        particles.z[i] += particles.vz[i] * dt;
        particles.lifetime[i] -= dt;
    }
}

// 성능 측정 함수
template<typename Function>
double measure_time(Function func, int iterations = 100) {
    auto start = std::chrono::high_resolution_clock::now();
    for (int i = 0; i < iterations; ++i) {
        func();
    }
    auto end = std::chrono::high_resolution_clock::now();
    return std::chrono::duration<double, std::milli>(end - start).count();
}

int main() {
    const size_t PARTICLE_COUNT = 1000000;
    const float DT = 0.016f;  // ~60 FPS
    const int ITERATIONS = 100;

    // AOS 테스트
    std::vector<Particle_AOS> particles_aos(PARTICLE_COUNT);
    for (size_t i = 0; i < PARTICLE_COUNT; ++i) {
        particles_aos[i] = {
            1.0f, 2.0f, 3.0f,      // position
            0.1f, 0.2f, 0.3f,      // velocity
            1.0f                   // lifetime
        };
    }

    double aos_time = measure_time(
        [&]() { update_particles_AOS(particles_aos, DT); },
        ITERATIONS
    );

    // SoA 테스트
    ParticleBuffer_SoA particles_soa;
    particles_soa.resize(PARTICLE_COUNT);

    for (size_t i = 0; i < PARTICLE_COUNT; ++i) {
        particles_soa.x[i] = 1.0f;
        particles_soa.y[i] = 2.0f;
        particles_soa.z[i] = 3.0f;
        particles_soa.vx[i] = 0.1f;
        particles_soa.vy[i] = 0.2f;
        particles_soa.vz[i] = 0.3f;
        particles_soa.lifetime[i] = 1.0f;
    }

    double soa_time = measure_time(
        [&]() { update_particles_SoA(particles_soa, DT); },
        ITERATIONS
    );

    // 결과 출력
    std::cout << std::fixed << std::setprecision(2);
    std::cout << "=== Memory Layout Performance Comparison ===\n";
    std::cout << "Particle count: " << PARTICLE_COUNT << "\n";
    std::cout << "Iterations: " << ITERATIONS << "\n\n";
    std::cout << "AOS (Array of Structs):\n";
    std::cout << "  Time: " << aos_time << " ms\n";
    std::cout << "  Memory per particle: " << sizeof(Particle_AOS) << " bytes\n\n";
    std::cout << "SoA (Structure of Arrays):\n";
    std::cout << "  Time: " << soa_time << " ms\n\n";
    std::cout << "Speedup (SoA / AOS): " << aos_time / soa_time << "x\n";

    return 0;
}
```

이 코드는 SoA가 캐시 효율성 측면에서 훨씬 우수함을 보여준다. AOS에서는 각 입자의 모든 속성이 메모리에 연속적으로 배치되어 있어서 위치를 읽을 때 불필요한 속도 데이터도 함께 캐시에 로드된다. SoA에서는 같은 속성의 데이터들만 메모리에 연속적으로 배치되어 있으므로 캐시를 더 효율적으로 사용한다.
  


## 18.3 컴파일러 최적화 활용법
컴파일러는 코드를 이해하고 다양한 최적화를 적용할 수 있다. 효과적인 최적화를 위해서는 컴파일러 옵션을 이해하고 활용해야 한다.

Visual Studio 2022에서의 최적화 옵션을 살펴보자.

```cpp
// compiler_optimization_demo.cpp
#include <iostream>
#include <vector>
#include <algorithm>
#include <cmath>

// 최적화를 피하는 함수 (벤치마킹용)
template<typename T>
inline volatile T avoid_optimization(const T& value) {
    volatile T v = value;
    return v;
}

// 계산 집약적인 함수 1: 순수 함수 (최적화 가능)
float pure_calculation(float x, float y) {
    // 순수 함수: 외부 상태에 의존하지 않음, 부작용 없음
    return std::sqrt(x * x + y * y);
}

// 계산 집약적인 함수 2: 함수 인라이닝 최적화 후보
inline float distance_3d(float x1, float y1, float z1,
                        float x2, float y2, float z2) {
    float dx = x2 - x1;
    float dy = y2 - y1;
    float dz = z2 - z1;
    return std::sqrt(dx * dx + dy * dy + dz * dz);
}

// constexpr를 사용한 컴파일 타임 계산
constexpr int factorial(int n) {
    return n <= 1 ? 1 : n * factorial(n - 1);
}

// 루프 언롤링 후보
void loop_unrolling_candidate(std::vector<int>& data) {
    // 컴파일러가 이 루프를 언롤링할 가능성이 있다
    for (int i = 0; i < 100; ++i) {
        data[i] *= 2;
    }
}

// 루프 벡터화 후보
void loop_vectorization_candidate(std::vector<float>& data) {
    // 컴파일러가 SIMD 명령어를 사용하여 벡터화할 가능성이 있다
    for (size_t i = 0; i < data.size(); ++i) {
        data[i] = data[i] * 2.0f + 1.0f;
    }
}

// 데드 코드 제거 예제
int dead_code_elimination_demo(int x) {
    int temp = x * 2;      // 이 값이 사용되지 않으면
    return x + 1;          // 컴파일러가 위 줄을 제거한다
}

// 공통 부분식 제거 (CSE)
float common_subexpression_elimination(float x, float y) {
    // 컴파일러가 x * y를 한 번만 계산한다
    float temp = x * y;
    return temp + temp;  // 2 * (x * y)와 같지만 한 번의 곱셈만
}

// 함수 포인터 vs 직접 호출
int sum_with_function_pointer(const std::vector<int>& data,
                               int (*op)(int)) {
    int result = 0;
    for (int v : data) {
        result += op(v);
    }
    return result;
}

int double_value(int x) { return x * 2; }

int sum_with_direct_call(const std::vector<int>& data) {
    int result = 0;
    for (int v : data) {
        result += double_value(v);
    }
    return result;
}

int main() {
    std::cout << "=== Compiler Optimization Examples ===\n\n";

    // constexpr 계산 (컴파일 타임)
    std::cout << "1. constexpr Evaluation (compile-time):\n";
    std::cout << "   factorial(10) = " << factorial(10) << "\n";
    std::cout << "   (계산이 컴파일 타임에 수행됨)\n\n";

    // 함수 인라이닝
    std::cout << "2. Function Inlining:\n";
    float dist = distance_3d(0, 0, 0, 3, 4, 0);
    std::cout << "   distance_3d(0, 0, 0, 3, 4, 0) = " << dist << "\n";
    std::cout << "   (inline 함수는 호출 오버헤드 없음)\n\n";

    // 루프 최적화 데모
    std::vector<int> data(100);
    for (int& v : data) {
        v = 1;
    }

    std::cout << "3. Loop Optimization:\n";
    std::cout << "   Before: data[50] = " << data[50] << "\n";
    loop_unrolling_candidate(data);
    std::cout << "   After:  data[50] = " << data[50] << "\n";
    std::cout << "   (루프 언롤링으로 성능 향상)\n\n";

    // 데드 코드 제거
    std::cout << "4. Dead Code Elimination:\n";
    int result = dead_code_elimination_demo(5);
    std::cout << "   Result: " << result << "\n";
    std::cout << "   (unused temp variable is eliminated)\n\n";

    // 공통 부분식 제거
    std::cout << "5. Common Subexpression Elimination:\n";
    float cse_result = common_subexpression_elimination(3.0f, 4.0f);
    std::cout << "   Result: " << cse_result << "\n";
    std::cout << "   (3.0 * 4.0 계산은 한 번만 수행)\n";

    return 0;
}
```

Visual Studio 2022에서의 주요 컴파일러 옵션을 정리하면 다음과 같다.

```
릴리스 빌드 설정:
- /O2: 최대 속도를 위한 최적화
- /Oi: 내장 함수 사용
- /Ot: 크기보다 속도 우선
- /Oy: 프레임 포인터 생략
- /GL: 전체 프로그램 최적화
- /LTCG: 링크 타임 코드 생성

추가 최적화 옵션:
- /arch:AVX2: AVX2 SIMD 지원
- /std:c++latest: 최신 C++ 표준
```

프로젝트 설정에서 이러한 옵션들을 설정할 수 있다.

```xml
<!-- Visual Studio 프로젝트 파일에서의 설정 -->
<PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Release|x64'">
  <WholeProgramOptimization>true</WholeProgramOptimization>
  <InlineFunctionExpansion>AnySuitable</InlineFunctionExpansion>
  <FavorSizeOrSpeed>Speed</FavorSizeOrSpeed>
  <OmitFramePointers>true</OmitFramePointers>
  <StringPooling>true</StringPooling>
  <RuntimeLibrary>MultiThreadedDLL</RuntimeLibrary>
  <EnableFunctionLevelLinking>true</EnableFunctionLevelLinking>
  <CLCompile>
    <PreprocessorDefinitions>NDEBUG;_WINDOWS;%(PreprocessorDefinitions)</PreprocessorDefinitions>
    <DebugInformationFormat>ProgramDatabase</DebugInformationFormat>
  </CLCompile>
</PropertyGroup>
```
  


## 18.4 프로파일링 기반 성능 튜닝
벤치마킹으로 성능 병목을 파악했다면, 이제 프로파일링으로 정확한 원인을 찾아야 한다. Visual Studio에 내장된 프로파일러를 사용하는 방법을 보자.

먼저 간단한 프로파일링 도구를 만들어보자.

```cpp
// profiler.hpp
#ifndef PROFILER_HPP
#define PROFILER_HPP

#include <string>
#include <map>
#include <vector>
#include <chrono>
#include <iostream>
#include <iomanip>
#include <algorithm>
#include <numeric>
#include <cmath>

namespace profiling {
    // 프로파일링 기록
    struct ProfileRecord {
        std::string name;
        long long duration_ns;
        std::chrono::high_resolution_clock::time_point timestamp;
    };

    // 간단한 프로파일러
    class Profiler {
    private:
        static std::vector<ProfileRecord> records_;
        static std::string current_scope_;
        static std::chrono::high_resolution_clock::time_point scope_start_;

    public:
        static void begin_scope(const std::string& name) {
            current_scope_ = name;
            scope_start_ = std::chrono::high_resolution_clock::now();
        }

        static void end_scope() {
            auto end = std::chrono::high_resolution_clock::now();
            long long duration = std::chrono::duration_cast<
                std::chrono::nanoseconds>(end - scope_start_).count();

            records_.push_back({
                current_scope_,
                duration,
                std::chrono::high_resolution_clock::now()
            });
        }

        static void print_report() {
            if (records_.empty()) {
                std::cout << "No profile data collected\n";
                return;
            }

            // 함수별로 데이터 그룹화
            std::map<std::string, std::vector<long long>> grouped;
            for (const auto& record : records_) {
                grouped[record.name].push_back(record.duration_ns);
            }

            std::cout << "\n=== Profiling Report ===\n";
            std::cout << std::left << std::setw(30) << "Function"
                     << std::right << std::setw(15) << "Calls"
                     << std::setw(15) << "Total (ms)"
                     << std::setw(15) << "Avg (us)"
                     << std::setw(15) << "Min (us)"
                     << std::setw(15) << "Max (us)" << "\n";
            std::cout << std::string(105, '-') << "\n";

            for (const auto& [name, times] : grouped) {
                double total_ms = std::accumulate(times.begin(), times.end(), 0LL) / 1e6;
                double avg_us = std::accumulate(times.begin(), times.end(), 0LL) / 1e3 / times.size();
                double min_us = *std::min_element(times.begin(), times.end()) / 1e3;
                double max_us = *std::max_element(times.begin(), times.end()) / 1e3;

                std::cout << std::left << std::setw(30) << name
                         << std::right << std::setw(15) << times.size()
                         << std::setw(15) << std::fixed << std::setprecision(3) << total_ms
                         << std::setw(15) << avg_us
                         << std::setw(15) << min_us
                         << std::setw(15) << max_us << "\n";
            }
        }

        static void clear() {
            records_.clear();
        }
    };

    // 정적 멤버 초기화
    std::vector<ProfileRecord> Profiler::records_;
    std::string Profiler::current_scope_;
    std::chrono::high_resolution_clock::time_point Profiler::scope_start_;

    // RAII를 사용한 스코프 프로파일러
    class ScopeProfiler {
    private:
        std::string name_;

    public:
        explicit ScopeProfiler(const std::string& name) : name_(name) {
            Profiler::begin_scope(name);
        }

        ~ScopeProfiler() {
            Profiler::end_scope();
        }
    };
}

// 편의 매크로
#define PROFILE_SCOPE(name) profiling::ScopeProfiler profiler_##__COUNTER__(name)

#endif // PROFILER_HPP
```

이제 프로파일러를 사용한 성능 분석 예제를 만들어보자.

```cpp
// profiling_example.cpp
#include "profiler.hpp"
#include <vector>
#include <algorithm>
#include <numeric>
#include <cmath>

// 다양한 성능의 함수들
void slow_algorithm(std::vector<int>& data) {
    PROFILE_SCOPE("slow_algorithm");
    
    // O(n²) 알고리즘
    for (size_t i = 0; i < data.size(); ++i) {
        for (size_t j = 0; j < data.size(); ++j) {
            data[i] += data[j];
        }
    }
}

void medium_algorithm(std::vector<int>& data) {
    PROFILE_SCOPE("medium_algorithm");
    
    // O(n log n) 알고리즘
    std::sort(data.begin(), data.end());
    std::reverse(data.begin(), data.end());
}

void fast_algorithm(std::vector<int>& data) {
    PROFILE_SCOPE("fast_algorithm");
    
    // O(n) 알고리즘
    std::transform(data.begin(), data.end(), data.begin(),
                  [](int x) { return x * 2; });
}

void algorithm_with_cache_misses(std::vector<int>& data) {
    PROFILE_SCOPE("algorithm_with_cache_misses");
    
    // 나쁜 캐시 지역성
    int stride = 64;  // 큰 스트라이드
    for (size_t i = 0; i < data.size(); i += stride) {
        data[i] = data[i] * 2;
    }
}

void algorithm_with_good_locality(std::vector<int>& data) {
    PROFILE_SCOPE("algorithm_with_good_locality");
    
    // 좋은 캐시 지역성
    for (size_t i = 0; i < data.size(); ++i) {
        data[i] = data[i] * 2;
    }
}

// 중첩 함수 호출의 프로파일링
void outer_function() {
    PROFILE_SCOPE("outer_function");
    
    std::vector<int> data(1000);
    std::iota(data.begin(), data.end(), 0);

    {
        PROFILE_SCOPE("inner_function_1");
        std::sort(data.begin(), data.end());
    }

    {
        PROFILE_SCOPE("inner_function_2");
        std::reverse(data.begin(), data.end());
    }
}

int main() {
    using namespace profiling;

    // 테스트 1: 다양한 알고리즘 비교
    std::cout << "=== Profiling Different Algorithms ===\n";

    std::vector<int> data1(1000);
    std::iota(data1.begin(), data1.end(), 0);

    std::vector<int> data2 = data1;
    fast_algorithm(data2);

    std::vector<int> data3 = data1;
    medium_algorithm(data3);

    std::vector<int> data4 = data1;
    slow_algorithm(data4);

    Profiler::print_report();
    Profiler::clear();

    // 테스트 2: 캐시 지역성 비교
    std::cout << "\n\n=== Profiling Cache Locality ===\n";

    std::vector<int> data5(1000000);
    std::iota(data5.begin(), data5.end(), 0);

    // 나쁜 캐시 지역성
    for (int i = 0; i < 100; ++i) {
        algorithm_with_cache_misses(data5);
    }

    // 좋은 캐시 지역성
    for (int i = 0; i < 100; ++i) {
        algorithm_with_good_locality(data5);
    }

    Profiler::print_report();
    Profiler::clear();

    // 테스트 3: 중첩 함수 호출
    std::cout << "\n\n=== Profiling Nested Functions ===\n";

    for (int i = 0; i < 10; ++i) {
        outer_function();
    }

    Profiler::print_report();

    return 0;
}
```

마지막으로 성능 최적화의 전체 프로세스를 보여주자.

```cpp
// optimization_workflow.cpp
// 최적화 전후 비교 예제

#include <vector>
#include <algorithm>
#include <numeric>
#include <chrono>
#include <iostream>
#include <iomanip>
#include <string>

// 비효율적인 구현
class StringProcessor_V1 {
public:
    static std::string process(const std::vector<std::string>& inputs) {
        std::string result;
        
        // 문제 1: 루프에서 문자열 연결 (반복적인 메모리 할당)
        for (const auto& input : inputs) {
            result += input;      // 매번 재할당
            result += ",";        // 매번 재할당
        }
        
        return result;
    }
};

// 최적화된 구현
class StringProcessor_V2 {
public:
    static std::string process(const std::vector<std::string>& inputs) {
        if (inputs.empty()) return "";
        
        // 개선 1: 필요한 크기를 미리 계산
        size_t total_size = 0;
        for (const auto& input : inputs) {
            total_size += input.size() + 1;  // 문자열 + 쉼표
        }
        total_size--;  // 마지막 쉼표 제거
        
        // 개선 2: reserve로 메모리 사전 할당
        std::string result;
        result.reserve(total_size);
        
        // 개선 3: append 사용 (더 효율적)
        for (size_t i = 0; i < inputs.size(); ++i) {
            if (i > 0) result.append(",");
            result.append(inputs[i]);
        }
        
        return result;
    }
};

// 더 최적화된 구현
class StringProcessor_V3 {
public:
    static std::string process(const std::vector<std::string>& inputs) {
        if (inputs.empty()) return "";
        
        // std::accumulate 사용
        std::string result = inputs[0];
        for (size_t i = 1; i < inputs.size(); ++i) {
            result += ',';
            result += inputs[i];
        }
        
        return result;
    }
};

// 성능 측정
template<typename Processor>
double benchmark_processor(const std::vector<std::string>& data,
                          int iterations) {
    auto start = std::chrono::high_resolution_clock::now();
    
    for (int i = 0; i < iterations; ++i) {
        volatile auto result = Processor::process(data);
        (void)result;
    }
    
    auto end = std::chrono::high_resolution_clock::now();
    return std::chrono::duration<double, std::milli>(end - start).count();
}

int main() {
    // 테스트 데이터 준비
    std::vector<std::string> data;
    for (int i = 0; i < 1000; ++i) {
        data.push_back("string_" + std::to_string(i));
    }

    const int ITERATIONS = 1000;

    std::cout << "=== String Processing Optimization ===\n";
    std::cout << "Data size: " << data.size() << " strings\n";
    std::cout << "Iterations: " << ITERATIONS << "\n\n";

    // V1: 비효율적
    double v1_time = benchmark_processor<StringProcessor_V1>(data, ITERATIONS);
    std::cout << "V1 (Inefficient):     " << std::fixed << std::setprecision(2)
             << v1_time << " ms\n";

    // V2: 최적화
    double v2_time = benchmark_processor<StringProcessor_V2>(data, ITERATIONS);
    std::cout << "V2 (Optimized):       " << v2_time << " ms\n";

    // V3: 더 최적화
    double v3_time = benchmark_processor<StringProcessor_V3>(data, ITERATIONS);
    std::cout << "V3 (More Optimized):  " << v3_time << " ms\n";

    // 성능 개선율 계산
    std::cout << "\n=== Performance Improvement ===\n";
    std::cout << "V2 vs V1: " << v1_time / v2_time << "x faster\n";
    std::cout << "V3 vs V1: " << v1_time / v3_time << "x faster\n";
    std::cout << "V3 vs V2: " << v2_time / v3_time << "x faster\n";

    return 0;
}
```

이 장에서 배운 성능 최적화의 핵심 원칙을 정리하면 다음과 같다. 첫째, 추측하지 말고 측정하라. 벤치마킹과 프로파일링을 통해 병목을 정확히 파악해야 한다. 둘째, 병목의 원인을 이해하라. 메모리 할당, 캐시 미스, 불필요한 복사 등 다양한 원인이 있을 수 있다. 셋째, 컴파일러를 믿고 활용하라. Modern C++의 최적화 기능들을 제대로 활용하면 컴파일러가 효율적인 코드를 생성한다. 넷째, 작은 최적화부터 큰 개선까지, 체계적으로 접근하라.

Modern C++은 `constexpr`, `inline`, 스마트 포인터, 이동 의미론 등을 통해 높은 성능과 안전성을 동시에 달성할 수 있는 도구를 제공한다. 올바른 프로파일링과 최적화를 통해 C++은 성능이 중요한 시스템에서도 안전하게 사용할 수 있는 언어다.     